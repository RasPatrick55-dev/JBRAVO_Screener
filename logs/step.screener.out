[2026-01-09T03:13:46.761602+00:00] START screener
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
2026-01-08 21:13:47,599 [INFO] __main__: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
2026-01-08 21:13:47,917 [INFO] __main__: [STAGE] fetch start
2026-01-08 21:13:48,786 [INFO] __main__: Asset meta ready: 12066 symbols (tradable US equities)
2026-01-08 21:13:48,800 [INFO] __main__: Asset metrics: total=13124 tradable_equities=12332 after_filters=12066
2026-01-08 21:13:48,801 [INFO] __main__: Asset sample: BFH.PRA:NYSE, NATH:NASDAQ, WIW:NYSE, NAT:NYSE, NAGE:NASDAQ
2026-01-08 21:13:48,834 [INFO] __main__: Universe sample size: 5881 (of 12066 tradable equities)
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\RasPa\miniconda3\Lib\logging\__init__.py", line 1153, in emit
    stream.write(msg + self.terminator)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RasPa\miniconda3\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2192' in position 75: character maps to <undefined>
Call stack:
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5929, in <module>
    raise SystemExit(main())
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5913, in main
    return _run()
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5819, in _run
    ) = _load_alpaca_universe(
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 2139, in _load_alpaca_universe
    universe_df = _apply_universe_hygiene(universe_df, asset_meta)
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 132, in _apply_universe_hygiene
    LOGGER.info("Universe hygiene filtered %d \u2192 %d symbols", before, int(filtered.shape[0]))
Message: 'Universe hygiene filtered %d \u2192 %d symbols'
Arguments: (5881, 4939)
2026-01-08 21:13:48,895 [INFO] __main__: Universe hygiene filtered 5881 \u2192 4939 symbols
2026-01-08 21:13:48,904 [INFO] __main__: Universe prefix counts: {'C': 45, 'A': 45, 'S': 43, 'B': 27, 'E': 21, 'F': 21, 'M': 19, 'N': 19, 'P': 19, 'T': 17, 'G': 17, 'H': 17, 'R': 17, 'O': 16, 'D': 15, 'I': 14, 'V': 14, 'W': 13, 'K': 13, 'L': 10, 'Z': 9, 'J': 5, 'U': 5, 'X': 4, 'Y': 3, 'Q': 2}
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\RasPa\miniconda3\Lib\logging\__init__.py", line 1153, in emit
    stream.write(msg + self.terminator)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RasPa\miniconda3\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2192' in position 112: character maps to <undefined>
Call stack:
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5929, in <module>
    raise SystemExit(main())
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5913, in main
    return _run()
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5819, in _run
    ) = _load_alpaca_universe(
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 2285, in _load_alpaca_universe
    LOGGER.info(
Message: 'Requesting %d trading days ending %s (%s \u2192 %s)'
Arguments: (750, '2026-01-09', '2023-01-12T00:00:00Z', '2026-01-09T23:59:59Z')
2026-01-08 21:13:49,004 [INFO] __main__: Requesting 750 trading days ending 2026-01-09 (2023-01-12T00:00:00Z \u2192 2026-01-09T23:59:59Z)
2026-01-08 21:13:50,883 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:13:50,883 [INFO] __main__: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~35639 elapsed=1.9s cache=miss
2026-01-08 21:13:52,605 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:13:52,605 [INFO] __main__: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32595 elapsed=1.7s cache=miss
2026-01-08 21:13:54,389 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:13:54,389 [INFO] __main__: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33019 elapsed=1.8s cache=miss
2026-01-08 21:13:56,120 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:13:56,121 [INFO] __main__: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32445 elapsed=1.7s cache=miss
2026-01-08 21:13:57,906 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:13:57,906 [INFO] __main__: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~33720 elapsed=1.8s cache=miss
2026-01-08 21:13:59,654 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:13:59,654 [INFO] __main__: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32593 elapsed=1.7s cache=miss
2026-01-08 21:14:03,030 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:14:03,030 [INFO] __main__: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34896 elapsed=3.4s cache=miss
2026-01-08 21:14:05,401 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:14:05,401 [INFO] __main__: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~32847 elapsed=2.4s cache=miss
2026-01-08 21:14:07,063 [WARNING] __main__: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-09\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
2026-01-08 21:14:07,064 [INFO] __main__: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33545 elapsed=1.7s cache=miss
2026-01-08 21:14:07,435 [INFO] __main__: Bars fetch metrics: batches=9 paged=9 pages=36 rows=301299 symbols_with_bars=414
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\RasPa\miniconda3\Lib\logging\__init__.py", line 1153, in emit
    stream.write(msg + self.terminator)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RasPa\miniconda3\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2192' in position 72: character maps to <undefined>
Call stack:
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5929, in <module>
    raise SystemExit(main())
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5913, in main
    return _run()
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 5819, in _run
    ) = _load_alpaca_universe(
  File "C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py", line 2362, in _load_alpaca_universe
    LOGGER.info(
Message: 'Bars window attempts: %s \u2192 used=%d'
Arguments: ([750], 750)
2026-01-08 21:14:07,435 [INFO] __main__: Bars window attempts: [750] \u2192 used=750
2026-01-08 21:14:07,436 [INFO] __main__: Symbols without bars (sample): ['CMDB', 'KCHV', 'DYOR', 'PELIR', 'SZZLR', 'ALUB', 'JBS', 'KCHVR', 'QSEA', 'SLGB']
2026-01-08 21:14:07,436 [INFO] __main__: Symbols dropped for insufficient history: 27
2026-01-08 21:14:09,171 [INFO] __main__: [STAGE] fetch end (rows=301299, elapsed=21.25s)
2026-01-08 21:14:10,621 [INFO] __main__: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=301299 symbols=423
2026-01-08 21:14:10,623 [WARNING] __main__: PyYAML unavailable; using built-in ranker defaults.
2026-01-08 21:14:10,661 [INFO] __main__: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
2026-01-08 21:14:10,931 [WARNING] __main__: PyYAML unavailable; using built-in ranker defaults.
2026-01-08 21:14:10,932 [INFO] __main__: [STAGE] coarse features start
2026-01-08 21:16:01,820 [INFO] __main__: [STAGE] coarse features end (rows=301299)
2026-01-08 21:16:01,820 [INFO] __main__: [STAGE] coarse rank start
2026-01-08 21:16:01,934 [INFO] __main__: [STAGE] coarse rank end (rows=423)
2026-01-08 21:16:01,941 [INFO] __main__: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=423)
2026-01-08 21:16:01,962 [INFO] __main__: [STAGE] full features start (shortlist=423)
2026-01-08 21:17:51,529 [INFO] __main__: [STAGE] full features end (rows=301299)
2026-01-08 21:17:51,664 [INFO] __main__: [STAGE] finalize candidates pruned rows=301299 -> 264852
2026-01-08 21:17:51,664 [INFO] __main__: [STAGE] full rank start
2026-01-08 21:17:51,783 [INFO] __main__: [STAGE] full rank end (rows=423)
2026-01-08 21:17:51,783 [INFO] __main__: [INFO] SENTIMENT_STAGE enter df_rows=423 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-09
2026-01-08 21:17:51,784 [INFO] __main__: [INFO] SENTIMENT_FETCH skipped reason=disabled
2026-01-08 21:17:51,785 [INFO] __main__: [STAGE] quality filters pruned rows=423 -> 77
2026-01-08 21:17:51,787 [INFO] __main__: [STAGE] gates start
2026-01-08 21:17:51,795 [INFO] __main__: [STAGE] gates end (candidates=0)
2026-01-08 21:17:54,983 [INFO] __main__: No candidates passed ranking gates; sample rejections: [{"reason": "INSUFFICIENT_HISTORY", "symbol": "KCHV"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "CMDB"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "PELIR"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "ALUB"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "DYOR"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "SZZLR"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "JBS"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "KCHVR"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "SLGB"}, {"reason": "INSUFFICIENT_HISTORY", "symbol": "QSEA"}]
2026-01-08 21:17:55,071 [INFO] __main__: [STAGE] predictions written: data\predictions\2026-01-09.csv (top_n=77)
2026-01-08 21:17:55,083 [INFO] __main__: Screener complete: 7577 symbols examined, 0 candidates.
[2026-01-09T03:17:55.205388+00:00] END screener rc=0 secs=248.4
[2026-01-18T03:20:36.773953+00:00] START screener
[2026-01-17 21:20:37,476] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:20:37,480] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:20:37,481] [WARNING]: [WARN] Detected test credential prefix; continuing without strict validation
[2026-01-17 21:20:37,481] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "test\u2026", "secret_len": 4}
[2026-01-17 21:20:37,777] [INFO]: [STAGE] fetch start
[2026-01-17 21:20:38,345] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 21:20:38,358] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 21:20:38,359] [INFO]: Asset sample: COPL.WS:NYSE, COPL.U:NYSE, AYTU:NASDAQ, CRMLW:NASDAQ, HDMV:ARCA
[2026-01-17 21:20:38,378] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 21:20:38,495] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 21:20:38,501] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 21:20:38,601] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 21:20:38,603] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:40,568] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:40,568] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=2.0s cache=miss
[2026-01-17 21:20:40,569] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:42,490] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:42,490] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.9s cache=miss
[2026-01-17 21:20:42,492] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:44,227] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:44,227] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 21:20:44,228] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:45,933] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:45,933] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 21:20:45,935] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:47,642] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:47,642] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 21:20:47,643] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:49,403] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:49,403] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.8s cache=miss
[2026-01-17 21:20:49,405] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:51,102] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:51,102] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-17 21:20:51,105] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:52,804] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:52,804] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-17 21:20:52,806] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:54,513] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:20:54,513] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 21:20:54,919] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 21:20:56,212] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 21:20:57,489] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 21:20:57,502] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 21:20:57,502] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 21:20:57,502] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 21:20:57,502] [INFO]: Fallback batches invoked: 1
[2026-01-17 21:20:57,502] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 21:20:59,436] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.66s)
[2026-01-17 21:20:59,436] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 21:21:01,958] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 21:21:03,500] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 21:21:03,502] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:21:03,544] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 21:21:03,933] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:21:03,933] [INFO]: [STAGE] coarse features start
[2026-01-17 21:23:04,254] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 21:23:04,255] [INFO]: [STAGE] coarse rank start
[2026-01-17 21:23:04,377] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 21:23:04,377] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 21:23:04,383] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 21:23:04,403] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 21:25:05,817] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 21:25:05,958] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 21:25:05,958] [INFO]: [STAGE] full rank start
[2026-01-17 21:25:06,078] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 21:25:06,079] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 21:25:06,079] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 21:25:06,081] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 21:25:06,081] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 21:25:11,474] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 21:25:11,477] [INFO]: [STAGE] gates start
[2026-01-17 21:25:11,488] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 21:25:15,383] [INFO]: [SUMMARY] run_ts=2026-01-18T03:20:37Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 21:25:15,481] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 21:25:17,875] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 21:25:20,317] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 21:25:20,317] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
ch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:49,712] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:49,712] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.7s cache=miss
[2026-01-17 21:23:49,713] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:51,616] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:51,617] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.9s cache=miss
[2026-01-17 21:23:51,617] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:53,382] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:53,382] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.8s cache=miss
[2026-01-17 21:23:53,382] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:55,088] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:55,089] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 21:23:55,089] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:56,806] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:56,806] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 21:23:56,806] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:58,642] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:23:58,642] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.8s cache=miss
[2026-01-17 21:23:58,642] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:24:00,430] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:24:00,430] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.8s cache=miss
[2026-01-17 21:24:00,431] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:24:02,201] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:24:02,201] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.8s cache=miss
[2026-01-17 21:24:02,201] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:24:04,105] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:24:04,105] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.9s cache=miss
[2026-01-17 21:24:04,496] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 21:24:05,742] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 21:24:06,984] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 21:24:06,995] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 21:24:06,996] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 21:24:06,996] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 21:24:06,996] [INFO]: Fallback batches invoked: 1
[2026-01-17 21:24:06,996] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 21:24:08,966] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.98s)
[2026-01-17 21:24:08,966] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 21:24:11,332] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 21:24:12,924] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 21:24:12,927] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:24:12,972] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 21:24:13,393] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:24:13,393] [INFO]: [STAGE] coarse features start
[2026-01-17 21:26:09,876] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 21:26:09,876] [INFO]: [STAGE] coarse rank start
[2026-01-17 21:26:09,997] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 21:26:09,997] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 21:26:10,003] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 21:26:10,023] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 21:28:07,934] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 21:28:08,072] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 21:28:08,072] [INFO]: [STAGE] full rank start
[2026-01-17 21:28:08,197] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 21:28:08,197] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 21:28:08,198] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 21:28:08,199] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 21:28:08,199] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 21:28:08,665] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 21:28:08,668] [INFO]: [STAGE] gates start
[2026-01-17 21:28:08,678] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 21:28:12,447] [INFO]: [SUMMARY] run_ts=2026-01-18T03:23:46Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 21:28:12,537] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 21:28:14,941] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 21:28:17,462] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 21:28:17,462] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T03:28:17.624938+00:00] END screener rc=0 secs=271.5
[2026-01-18T03:28:37.840862+00:00] START screener
[2026-01-17 21:28:38,547] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:28:38,550] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:28:38,551] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 21:28:38,731] [INFO]: [STAGE] fetch start
[2026-01-17 21:28:39,401] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 21:28:39,416] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 21:28:39,417] [INFO]: Asset sample: CDXS:NASDAQ, HDV:ARCA, COPX:ARCA, CDZI:NASDAQ, COPP:NASDAQ
[2026-01-17 21:28:39,437] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 21:28:39,552] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 21:28:39,556] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 21:28:39,658] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 21:28:39,659] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:41,392] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:41,392] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.7s cache=miss
[2026-01-17 21:28:41,392] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:43,235] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:43,235] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.8s cache=miss
[2026-01-17 21:28:43,235] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:44,878] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:44,878] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.6s cache=miss
[2026-01-17 21:28:44,879] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:46,642] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:46,642] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.8s cache=miss
[2026-01-17 21:28:46,643] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:48,382] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:48,382] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 21:28:48,383] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:50,026] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:50,026] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.6s cache=miss
[2026-01-17 21:28:50,027] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:51,725] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:51,726] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-17 21:28:51,726] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:53,477] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:53,477] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.8s cache=miss
[2026-01-17 21:28:53,478] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:55,271] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:28:55,271] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.8s cache=miss
[2026-01-17 21:28:55,622] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 21:28:56,928] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 21:28:58,195] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 21:28:58,204] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 21:28:58,204] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 21:28:58,204] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 21:28:58,205] [INFO]: Fallback batches invoked: 1
[2026-01-17 21:28:58,205] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 21:29:00,071] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.34s)
[2026-01-17 21:29:00,071] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 21:29:02,606] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 21:29:04,111] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 21:29:04,113] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:29:04,154] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 21:29:04,549] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:29:04,549] [INFO]: [STAGE] coarse features start
[2026-01-17 21:31:02,720] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 21:31:02,720] [INFO]: [STAGE] coarse rank start
[2026-01-17 21:31:02,846] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 21:31:02,846] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 21:31:02,852] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 21:31:02,876] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 21:32:59,622] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 21:32:59,761] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 21:32:59,761] [INFO]: [STAGE] full rank start
[2026-01-17 21:32:59,880] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 21:32:59,881] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 21:32:59,881] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 21:32:59,882] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 21:32:59,883] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 21:33:00,405] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 21:33:00,408] [INFO]: [STAGE] gates start
[2026-01-17 21:33:00,417] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 21:33:04,241] [INFO]: [SUMMARY] run_ts=2026-01-18T03:28:38Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 21:33:04,336] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 21:33:07,217] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 21:33:09,682] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 21:33:09,683] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T03:33:09.835540+00:00] END screener rc=0 secs=272.0
[2026-01-18T03:37:38.283482+00:00] START screener
[2026-01-17 21:37:38,951] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:37:38,954] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:37:38,956] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 21:37:39,144] [INFO]: [STAGE] fetch start
[2026-01-17 21:37:39,737] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 21:37:39,752] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 21:37:39,753] [INFO]: Asset sample: COPL.WS:NYSE, AFCG:NASDAQ, HDV:ARCA, HDUS:ARCA, HDSN:NASDAQ
[2026-01-17 21:37:39,772] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 21:37:39,883] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 21:37:39,887] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 21:37:39,987] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 21:37:39,988] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:41,737] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:41,737] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.7s cache=miss
[2026-01-17 21:37:41,738] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:43,532] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:43,532] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.8s cache=miss
[2026-01-17 21:37:43,532] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:45,248] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:45,248] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 21:37:45,248] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:46,845] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:46,845] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.6s cache=miss
[2026-01-17 21:37:46,846] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:48,545] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:48,546] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 21:37:48,546] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:50,251] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:50,251] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.7s cache=miss
[2026-01-17 21:37:50,252] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:52,034] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:52,035] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.8s cache=miss
[2026-01-17 21:37:52,035] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:53,816] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:53,816] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.8s cache=miss
[2026-01-17 21:37:53,817] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:55,522] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:37:55,522] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 21:37:55,853] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 21:37:57,120] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 21:37:58,313] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 21:37:58,324] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 21:37:58,324] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 21:37:58,324] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 21:37:58,324] [INFO]: Fallback batches invoked: 1
[2026-01-17 21:37:58,324] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 21:38:00,092] [INFO]: [STAGE] fetch end (rows=299234, elapsed=20.95s)
[2026-01-17 21:38:00,092] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 21:38:02,505] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 21:38:03,961] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 21:38:03,963] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:38:04,003] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 21:38:04,378] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:38:04,378] [INFO]: [STAGE] coarse features start
[2026-01-17 21:39:54,637] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 21:39:54,638] [INFO]: [STAGE] coarse rank start
[2026-01-17 21:39:54,749] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 21:39:54,749] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 21:39:54,756] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 21:39:54,775] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 21:41:43,725] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 21:41:43,847] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 21:41:43,847] [INFO]: [STAGE] full rank start
[2026-01-17 21:41:43,960] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 21:41:43,960] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 21:41:43,960] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 21:41:43,962] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 21:41:43,962] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 21:41:44,455] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 21:41:44,457] [INFO]: [STAGE] gates start
[2026-01-17 21:41:44,467] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 21:41:47,973] [INFO]: [SUMMARY] run_ts=2026-01-18T03:37:39Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 21:41:48,062] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 21:41:50,440] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 21:41:52,866] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 21:41:52,866] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T03:41:53.004294+00:00] END screener rc=0 secs=254.7
[2026-01-18T03:53:28.196463+00:00] START screener
[2026-01-17 21:53:28,854] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:53:28,857] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 21:53:28,858] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 21:53:29,173] [INFO]: [STAGE] fetch start
[2026-01-17 21:53:29,751] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 21:53:29,765] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 21:53:29,766] [INFO]: Asset sample: COPL.WS:NYSE, AFCG:NASDAQ, HDV:ARCA, HDUS:ARCA, HDSN:NASDAQ
[2026-01-17 21:53:29,785] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 21:53:29,893] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 21:53:29,898] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 21:53:29,999] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 21:53:30,000] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:31,802] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:31,802] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-17 21:53:31,803] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:33,591] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:33,591] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.8s cache=miss
[2026-01-17 21:53:33,591] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:35,264] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:35,264] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 21:53:35,264] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:36,981] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:36,981] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 21:53:36,981] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:38,681] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:38,681] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 21:53:38,682] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:40,992] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:40,992] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=2.3s cache=miss
[2026-01-17 21:53:40,992] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:43,024] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:43,024] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=2.0s cache=miss
[2026-01-17 21:53:43,025] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:44,729] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:44,729] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-17 21:53:44,729] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:46,476] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 21:53:46,476] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 21:53:46,869] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 21:53:48,213] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 21:53:49,483] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 21:53:49,494] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 21:53:49,494] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 21:53:49,494] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 21:53:49,494] [INFO]: Fallback batches invoked: 1
[2026-01-17 21:53:49,494] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 21:53:51,392] [INFO]: [STAGE] fetch end (rows=299234, elapsed=22.22s)
[2026-01-17 21:53:51,392] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 21:53:53,767] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 21:53:55,259] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 21:53:55,262] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:53:55,303] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 21:53:55,707] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 21:53:55,707] [INFO]: [STAGE] coarse features start
[2026-01-17 21:55:55,109] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 21:55:55,109] [INFO]: [STAGE] coarse rank start
[2026-01-17 21:55:55,225] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 21:55:55,225] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 21:55:55,233] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 21:55:55,255] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 21:57:52,639] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 21:57:52,779] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 21:57:52,779] [INFO]: [STAGE] full rank start
[2026-01-17 21:57:52,897] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 21:57:52,897] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 21:57:52,898] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 21:57:52,899] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 21:57:52,899] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 21:57:53,372] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 21:57:53,375] [INFO]: [STAGE] gates start
[2026-01-17 21:57:53,386] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 21:57:57,346] [INFO]: [SUMMARY] run_ts=2026-01-18T03:53:29Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 21:57:57,437] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 21:57:59,791] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 21:58:02,224] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 21:58:02,224] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T03:58:02.373543+00:00] END screener rc=0 secs=274.2
[2026-01-18T04:28:58.751322+00:00] START screener
[2026-01-17 22:28:59,490] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 22:28:59,494] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 22:28:59,495] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 22:28:59,706] [INFO]: [STAGE] fetch start
[2026-01-17 22:29:00,304] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 22:29:00,318] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 22:29:00,319] [INFO]: Asset sample: COPL.WS:NYSE, COPL.U:NYSE, AYTU:NASDAQ, CRMLW:NASDAQ, HDMV:ARCA
[2026-01-17 22:29:00,338] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 22:29:00,451] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 22:29:00,457] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 22:29:00,558] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 22:29:00,558] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:02,363] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:02,363] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-17 22:29:02,363] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:04,155] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:04,155] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.8s cache=miss
[2026-01-17 22:29:04,155] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:05,901] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:05,901] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 22:29:05,902] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:07,657] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:07,657] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.8s cache=miss
[2026-01-17 22:29:07,658] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:09,374] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:09,374] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 22:29:09,375] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:11,020] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:11,020] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.6s cache=miss
[2026-01-17 22:29:11,020] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:12,711] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:12,711] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-17 22:29:12,711] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:14,483] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:14,483] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.8s cache=miss
[2026-01-17 22:29:14,483] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:16,196] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:29:16,196] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 22:29:16,560] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 22:29:17,843] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 22:29:19,135] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 22:29:19,146] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 22:29:19,146] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 22:29:19,147] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 22:29:19,147] [INFO]: Fallback batches invoked: 1
[2026-01-17 22:29:19,147] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 22:29:21,049] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.34s)
[2026-01-17 22:29:21,050] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 22:29:23,502] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 22:29:25,021] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 22:29:25,025] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 22:29:25,066] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 22:29:25,452] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 22:29:25,452] [INFO]: [STAGE] coarse features start
[2026-01-17 22:31:22,684] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 22:31:22,684] [INFO]: [STAGE] coarse rank start
[2026-01-17 22:31:22,799] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 22:31:22,799] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 22:31:22,807] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 22:31:22,827] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 22:33:18,700] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 22:33:18,832] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 22:33:18,832] [INFO]: [STAGE] full rank start
[2026-01-17 22:33:18,946] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 22:33:18,946] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 22:33:18,947] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 22:33:18,948] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 22:33:18,949] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 22:33:28,742] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 22:33:28,745] [INFO]: [STAGE] gates start
[2026-01-17 22:33:28,756] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 22:33:32,367] [INFO]: [SUMMARY] run_ts=2026-01-18T04:28:59Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 22:33:32,462] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 22:33:34,850] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 22:33:37,547] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 22:33:37,548] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T04:33:37.688309+00:00] END screener rc=0 secs=278.9
[2026-01-18T04:46:51.415713+00:00] START screener
[2026-01-17 22:46:52,084] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 22:46:52,087] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 22:46:52,088] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 22:46:52,310] [INFO]: [STAGE] fetch start
[2026-01-17 22:46:52,940] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 22:46:52,953] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 22:46:52,955] [INFO]: Asset sample: CWH:NYSE, CWI:ARCA, CWK:NYSE, CWS:ARCA, CWST:NASDAQ
[2026-01-17 22:46:52,974] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 22:46:53,084] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 22:46:53,088] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 22:46:53,192] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 22:46:53,193] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:46:55,025] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:46:55,026] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-17 22:46:55,026] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:46:56,808] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:46:56,808] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.8s cache=miss
[2026-01-17 22:46:56,808] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:46:58,475] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:46:58,475] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 22:46:58,475] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:00,134] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:00,134] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 22:47:00,135] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:01,893] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:01,893] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.8s cache=miss
[2026-01-17 22:47:01,893] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:03,512] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:03,513] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.6s cache=miss
[2026-01-17 22:47:03,513] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:05,327] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:05,327] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.8s cache=miss
[2026-01-17 22:47:05,328] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:07,129] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:07,129] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.8s cache=miss
[2026-01-17 22:47:07,130] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:08,866] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 22:47:08,866] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 22:47:09,194] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 22:47:10,481] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 22:47:11,707] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 22:47:11,717] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 22:47:11,717] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 22:47:11,717] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 22:47:11,717] [INFO]: Fallback batches invoked: 1
[2026-01-17 22:47:11,717] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 22:47:13,563] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.25s)
[2026-01-17 22:47:13,564] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 22:47:15,923] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 22:47:17,403] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 22:47:17,405] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 22:47:17,445] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 22:47:17,827] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 22:47:17,827] [INFO]: [STAGE] coarse features start
[2026-01-17 22:49:11,383] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 22:49:11,384] [INFO]: [STAGE] coarse rank start
[2026-01-17 22:49:11,496] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 22:49:11,496] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 22:49:11,504] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 22:49:11,525] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 22:51:08,505] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 22:51:08,645] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 22:51:08,645] [INFO]: [STAGE] full rank start
[2026-01-17 22:51:08,769] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 22:51:08,770] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 22:51:08,770] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 22:51:08,772] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 22:51:08,772] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 22:51:09,224] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 22:51:09,227] [INFO]: [STAGE] gates start
[2026-01-17 22:51:09,236] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 22:51:13,075] [INFO]: [SUMMARY] run_ts=2026-01-18T04:46:52Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 22:51:13,176] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 22:51:15,556] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 22:51:18,029] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 22:51:18,029] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T04:51:18.171489+00:00] END screener rc=0 secs=266.8
[2026-01-18T05:16:58.288508+00:00] START screener
[2026-01-17 23:16:58,942] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 23:16:58,946] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 23:16:58,948] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 23:16:59,276] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-17 23:16:59,276] [INFO]: [STAGE] fetch start
[2026-01-17 23:16:59,854] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 23:16:59,868] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 23:16:59,869] [INFO]: Asset sample: CORB:ARCA, FAX:AMEX, COPY:ARCA, COPX:ARCA, AZN:NASDAQ
[2026-01-17 23:16:59,888] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 23:16:59,997] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 23:17:00,001] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 23:17:00,109] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 23:17:00,110] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:01,999] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:01,999] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.9s cache=miss
[2026-01-17 23:17:01,999] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:03,927] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:03,927] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.9s cache=miss
[2026-01-17 23:17:03,928] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:05,607] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:05,607] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 23:17:05,608] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:07,265] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:07,265] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 23:17:07,266] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:09,088] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:09,088] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.8s cache=miss
[2026-01-17 23:17:09,088] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:10,814] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:10,814] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.7s cache=miss
[2026-01-17 23:17:10,814] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:12,582] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:12,582] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.8s cache=miss
[2026-01-17 23:17:12,582] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:14,286] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:14,286] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-17 23:17:14,287] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:16,083] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:17:16,083] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.8s cache=miss
[2026-01-17 23:17:16,457] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 23:17:17,727] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 23:17:18,999] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 23:17:19,009] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 23:17:19,009] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 23:17:19,010] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 23:17:19,010] [INFO]: Fallback batches invoked: 1
[2026-01-17 23:17:19,010] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 23:17:20,900] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.62s)
[2026-01-17 23:17:20,901] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 23:17:23,276] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 23:17:24,784] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 23:17:24,787] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 23:17:24,830] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 23:17:25,234] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 23:17:25,234] [INFO]: [STAGE] coarse features start
[2026-01-17 23:19:22,592] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 23:19:22,593] [INFO]: [STAGE] coarse rank start
[2026-01-17 23:19:22,714] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 23:19:22,715] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 23:19:22,722] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 23:19:22,745] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 23:21:20,071] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 23:21:20,215] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 23:21:20,215] [INFO]: [STAGE] full rank start
[2026-01-17 23:21:20,346] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 23:21:20,346] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 23:21:20,347] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 23:21:20,348] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 23:21:20,349] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 23:21:20,841] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 23:21:20,843] [INFO]: [STAGE] gates start
[2026-01-17 23:21:20,854] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 23:21:24,885] [INFO]: [SUMMARY] run_ts=2026-01-18T05:16:59Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 23:21:24,981] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 23:21:27,325] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 23:21:29,799] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 23:21:29,800] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T05:21:29.941552+00:00] END screener rc=0 secs=271.7
[2026-01-18T05:34:34.406565+00:00] START screener
[2026-01-17 23:34:35,067] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 23:34:35,070] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 23:34:35,072] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 23:34:35,332] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-17 23:34:35,332] [INFO]: [STAGE] fetch start
[2026-01-17 23:34:35,955] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 23:34:35,969] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 23:34:35,970] [INFO]: Asset sample: CDZI:NASDAQ, FAX:AMEX, AYTU:NASDAQ, COPL.U:NYSE, COPL:NYSE
[2026-01-17 23:34:35,989] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 23:34:36,103] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 23:34:36,108] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 23:34:36,210] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 23:34:36,211] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:38,004] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:38,004] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-17 23:34:38,004] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:39,863] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:39,863] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.9s cache=miss
[2026-01-17 23:34:39,863] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:41,452] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:41,452] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.6s cache=miss
[2026-01-17 23:34:41,453] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:43,133] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:43,133] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 23:34:43,133] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:44,837] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:44,837] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 23:34:44,837] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:46,438] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:46,439] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.6s cache=miss
[2026-01-17 23:34:46,439] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:48,186] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:48,186] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-17 23:34:48,186] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:49,912] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:49,912] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-17 23:34:49,912] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:51,594] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:34:51,594] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 23:34:51,946] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 23:34:53,210] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 23:34:54,510] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 23:34:54,521] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 23:34:54,521] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 23:34:54,521] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 23:34:54,521] [INFO]: Fallback batches invoked: 1
[2026-01-17 23:34:54,521] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 23:34:56,394] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.06s)
[2026-01-17 23:34:56,394] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 23:34:58,830] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 23:35:00,356] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 23:35:00,359] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 23:35:00,399] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 23:35:00,781] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 23:35:00,781] [INFO]: [STAGE] coarse features start
[2026-01-17 23:36:57,212] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 23:36:57,212] [INFO]: [STAGE] coarse rank start
[2026-01-17 23:36:57,337] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 23:36:57,337] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 23:36:57,346] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 23:36:57,366] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-17 23:38:55,867] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-17 23:38:56,007] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-17 23:38:56,007] [INFO]: [STAGE] full rank start
[2026-01-17 23:38:56,126] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-17 23:38:56,126] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-17 23:38:56,127] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-17 23:38:56,128] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-17 23:38:56,129] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-17 23:38:56,956] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-17 23:38:56,958] [INFO]: [STAGE] gates start
[2026-01-17 23:38:56,967] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-17 23:39:00,522] [INFO]: [SUMMARY] run_ts=2026-01-18T05:34:35Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-17 23:39:00,611] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-17 23:39:03,324] [WARNING]: [WARN] DB_INGEST_FAILED table=screener_candidates err=can't adapt type 'NAType'
[2026-01-17 23:39:05,845] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-17 23:39:05,845] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T05:39:06.002457+00:00] END screener rc=0 secs=271.6
[2026-01-18T05:54:01.542818+00:00] START screener
[2026-01-17 23:54:02,216] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 23:54:02,219] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-17 23:54:02,222] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-17 23:54:02,453] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-17 23:54:02,453] [INFO]: [STAGE] fetch start
[2026-01-17 23:54:03,078] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-17 23:54:03,090] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-17 23:54:03,091] [INFO]: Asset sample: HDMV:ARCA, HDLB:ARCA, CDX:ARCA, HDL:NASDAQ, AZTA:NASDAQ
[2026-01-17 23:54:03,110] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-17 23:54:03,220] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-17 23:54:03,228] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-17 23:54:03,327] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-17 23:54:03,329] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:05,121] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:05,121] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-17 23:54:05,121] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:06,917] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:06,917] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.8s cache=miss
[2026-01-17 23:54:06,917] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:08,589] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:08,590] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-17 23:54:08,591] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:10,317] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:10,317] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.7s cache=miss
[2026-01-17 23:54:10,319] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:12,020] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:12,021] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.7s cache=miss
[2026-01-17 23:54:12,021] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:13,716] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:13,716] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.7s cache=miss
[2026-01-17 23:54:13,719] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:15,462] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:15,462] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-17 23:54:15,464] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:17,158] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:17,158] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-17 23:54:17,158] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:18,898] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-17 23:54:18,899] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-17 23:54:19,250] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-17 23:54:20,560] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-17 23:54:21,877] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-17 23:54:21,888] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-17 23:54:21,888] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-17 23:54:21,888] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-17 23:54:21,888] [INFO]: Fallback batches invoked: 1
[2026-01-17 23:54:21,888] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-17 23:54:23,865] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.41s)
[2026-01-17 23:54:23,865] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-17 23:54:26,229] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-17 23:54:27,767] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-17 23:54:27,769] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 23:54:27,813] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-17 23:54:28,210] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-17 23:54:28,211] [INFO]: [STAGE] coarse features start
[2026-01-17 23:58:48,809] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-17 23:58:48,809] [INFO]: [STAGE] coarse rank start
[2026-01-17 23:58:48,923] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-17 23:58:48,924] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-17 23:58:48,931] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-17 23:58:48,952] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-18 00:00:47,772] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-18 00:00:47,904] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-18 00:00:47,904] [INFO]: [STAGE] full rank start
[2026-01-18 00:00:48,025] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-18 00:00:48,026] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 00:00:48,026] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 00:00:48,028] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-18 00:00:48,028] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 00:00:48,804] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-18 00:00:48,807] [INFO]: [STAGE] gates start
[2026-01-18 00:00:48,817] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-18 00:00:52,490] [INFO]: [SUMMARY] run_ts=2026-01-18T05:54:02Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-18 00:00:52,580] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-18 00:00:55,004] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=5
[2026-01-18 00:00:55,196] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=5
[2026-01-18 00:00:57,762] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 00:00:57,762] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T06:00:57.939508+00:00] END screener rc=0 secs=416.4
[2026-01-18T06:08:27.434549+00:00] START screener
[2026-01-18 00:08:28,083] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:08:28,086] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:08:28,088] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 00:08:28,322] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 00:08:28,323] [INFO]: [STAGE] fetch start
[2026-01-18 00:08:28,885] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 00:08:28,898] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 00:08:28,899] [INFO]: Asset sample: A:NYSE, AEE:NYSE, AIRT:NASDAQ, AISPW:NASDAQ, APT:AMEX
[2026-01-18 00:08:28,917] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 00:08:29,021] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 00:08:29,025] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 00:08:29,131] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 00:08:29,131] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:30,888] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:30,888] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-18 00:08:30,888] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:32,756] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:32,756] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.9s cache=miss
[2026-01-18 00:08:32,756] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:34,430] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:34,430] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-18 00:08:34,430] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:36,062] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:36,062] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=1.6s cache=miss
[2026-01-18 00:08:36,062] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:37,838] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:37,838] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.8s cache=miss
[2026-01-18 00:08:37,838] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:39,594] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:39,594] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.8s cache=miss
[2026-01-18 00:08:39,594] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:41,322] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:41,322] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-18 00:08:41,322] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:42,989] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:42,989] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-18 00:08:42,990] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:44,828] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:08:44,828] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.8s cache=miss
[2026-01-18 00:08:45,209] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-18 00:08:46,473] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-18 00:08:47,737] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 00:08:47,749] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-18 00:08:47,749] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 00:08:47,749] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 00:08:47,749] [INFO]: Fallback batches invoked: 1
[2026-01-18 00:08:47,749] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-18 00:08:49,579] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.26s)
[2026-01-18 00:08:49,579] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 00:08:51,969] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 00:08:53,507] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-18 00:08:53,510] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-18 00:08:53,549] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 00:08:53,927] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-18 00:08:53,927] [INFO]: [STAGE] coarse features start
[2026-01-18 00:10:48,550] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-18 00:10:48,550] [INFO]: [STAGE] coarse rank start
[2026-01-18 00:10:48,665] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-18 00:10:48,665] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-18 00:10:48,673] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-18 00:10:48,693] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-18 00:12:41,448] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-18 00:12:41,588] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-18 00:12:41,588] [INFO]: [STAGE] full rank start
[2026-01-18 00:12:41,712] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-18 00:12:41,712] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 00:12:41,713] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 00:12:41,714] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-18 00:12:41,714] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 00:12:52,509] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-18 00:12:52,511] [INFO]: [STAGE] gates start
[2026-01-18 00:12:52,519] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-18 00:12:56,410] [INFO]: [SUMMARY] run_ts=2026-01-18T06:08:28Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-18 00:12:56,501] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-18 00:12:58,939] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=5
[2026-01-18 00:12:59,406] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=5
[2026-01-18 00:13:01,849] [INFO]: [INFO] SCREENER_CANDIDATES_PRUNED run_date=2026-01-16 deleted=13
[2026-01-18 00:13:04,310] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 00:13:04,310] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T06:13:04.453147+00:00] END screener rc=0 secs=277.0
[2026-01-18T06:18:39.309223+00:00] START screener
[2026-01-18 00:18:39,986] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:18:39,990] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:18:39,992] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 00:18:40,169] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 00:18:40,169] [INFO]: [STAGE] fetch start
[2026-01-18 00:18:40,771] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 00:18:40,785] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 00:18:40,786] [INFO]: Asset sample: COPL.WS:NYSE, AFCG:NASDAQ, HDV:ARCA, HDUS:ARCA, HDSN:NASDAQ
[2026-01-18 00:18:40,804] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 00:18:40,911] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 00:18:40,916] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 00:18:41,012] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 00:18:41,013] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:42,782] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:42,782] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~33604 elapsed=1.8s cache=miss
[2026-01-18 00:18:42,783] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:44,493] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:44,493] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~34544 elapsed=1.7s cache=miss
[2026-01-18 00:18:44,493] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:46,192] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:46,192] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~32405 elapsed=1.7s cache=miss
[2026-01-18 00:18:46,192] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:48,675] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:48,675] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33006 elapsed=2.5s cache=miss
[2026-01-18 00:18:48,675] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:50,318] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:50,318] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32261 elapsed=1.6s cache=miss
[2026-01-18 00:18:50,319] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:51,943] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:51,943] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31774 elapsed=1.6s cache=miss
[2026-01-18 00:18:51,944] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:53,628] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:53,629] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34430 elapsed=1.7s cache=miss
[2026-01-18 00:18:53,629] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:55,343] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:55,343] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33943 elapsed=1.7s cache=miss
[2026-01-18 00:18:55,343] [WARNING]: Failed to read cached batch data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:56,996] [WARNING]: Failed to persist batch cache data\cache\bars_1d_iex\2026-01-16\0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-18 00:18:56,996] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~33632 elapsed=1.7s cache=miss
[2026-01-18 00:18:57,320] [INFO]: [BARS_ACCEPT] accepted=425 dropped_missing=25
[2026-01-18 00:18:58,601] [INFO]: [BARS_RETRY] retried=25 recovered=0
[2026-01-18 00:18:59,832] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 00:18:59,842] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=299234 symbols_with_bars=414
[2026-01-18 00:18:59,842] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 00:18:59,842] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 00:18:59,842] [INFO]: Fallback batches invoked: 1
[2026-01-18 00:18:59,842] [INFO]: Symbols dropped for insufficient history: 25
[2026-01-18 00:19:01,644] [INFO]: [STAGE] fetch end (rows=299234, elapsed=21.47s)
[2026-01-18 00:19:01,644] [INFO]: [BARS_DIAG] feed=iex requested=500 with_bars=425 missing=75 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 00:19:04,038] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 00:19:05,501] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=299234 symbols=425
[2026-01-18 00:19:05,503] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-18 00:19:05,541] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 00:19:05,915] [WARNING]: PyYAML unavailable; using built-in ranker defaults.
[2026-01-18 00:19:05,915] [INFO]: [STAGE] coarse features start
[2026-01-18 00:20:55,418] [INFO]: [STAGE] coarse features end (rows=299234)
[2026-01-18 00:20:55,418] [INFO]: [STAGE] coarse rank start
[2026-01-18 00:20:55,529] [INFO]: [INFO] Coarse rank boundary rows_in=425 score_non_null=425 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,Score,score_breakdown,coarse_score
[2026-01-18 00:20:55,529] [INFO]: [STAGE] coarse rank end (rows=425)
[2026-01-18 00:20:55,537] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=425)
[2026-01-18 00:20:55,556] [INFO]: [STAGE] full features start (shortlist=425)
[2026-01-18 00:22:45,596] [INFO]: [STAGE] full features end (rows=299234)
[2026-01-18 00:22:45,737] [INFO]: [STAGE] finalize candidates pruned rows=299234 -> 265885
[2026-01-18 00:22:45,737] [INFO]: [STAGE] full rank start
[2026-01-18 00:22:45,854] [INFO]: [STAGE] full rank end (rows=425)
[2026-01-18 00:22:45,855] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=425 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 00:22:45,855] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 00:22:45,857] [INFO]: [STAGE] quality filters pruned rows=425 -> 77
[2026-01-18 00:22:45,857] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 00:22:46,485] [INFO]: [INFO] ML_RANK weight=0.30 rows=77 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.1695 model=data\models\rank_model.joblib
[2026-01-18 00:22:46,487] [INFO]: [STAGE] gates start
[2026-01-18 00:22:46,496] [INFO]: [STAGE] gates end (candidates=5)
[2026-01-18 00:22:49,911] [INFO]: [SUMMARY] run_ts=2026-01-18T06:18:40Z mode=screener symbols_in=7604 with_bars=425 coarse_rows=425 shortlist_rows=425 final_rows=5 gated_rows=5 fallback_used=false db_ingest_rows=5
[2026-01-18 00:22:50,000] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=77)
[2026-01-18 00:22:52,466] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=5
[2026-01-18 00:22:52,746] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=5
[2026-01-18 00:22:57,685] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 00:22:57,686] [INFO]: Screener complete: 7604 symbols examined, 5 candidates.
[2026-01-18T06:22:57.837074+00:00] END screener rc=0 secs=258.5
[2026-01-18T06:30:05.130532+00:00] START screener
[2026-01-18 00:30:05,893] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:30:05,897] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:30:05,902] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 00:30:06,112] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 00:30:06,112] [INFO]: [STAGE] fetch start
[2026-01-18 00:30:06,732] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 00:30:06,744] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 00:30:06,745] [INFO]: Asset sample: HDL:NASDAQ, AZ:NASDAQ, FAX:AMEX, AYTU:NASDAQ, CDXS:NASDAQ
[2026-01-18 00:30:06,780] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 00:30:06,876] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 00:30:06,882] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 00:30:06,985] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 00:30:07,142] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.2s cache=hit
[2026-01-18 00:30:07,175] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 00:30:07,224] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 00:30:07,274] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-18 00:30:07,321] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 00:30:07,370] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 00:30:07,405] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 00:30:07,456] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.1s cache=hit
[2026-01-18 00:30:07,501] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 00:30:07,851] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 00:30:31,413] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 00:30:32,627] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 00:30:32,636] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 00:30:32,636] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 00:30:32,636] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 00:30:32,636] [INFO]: Fallback batches invoked: 1
[2026-01-18 00:30:32,636] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 00:30:35,053] [INFO]: [STAGE] fetch end (rows=364439, elapsed=28.94s)
[2026-01-18 00:30:35,053] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 00:30:37,448] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 00:30:39,309] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 00:30:39,392] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 00:30:39,841] [INFO]: [STAGE] coarse features start
[2026-01-18 00:32:42,935] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 00:32:42,935] [INFO]: [STAGE] coarse rank start
[2026-01-18 00:32:43,167] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 00:32:43,167] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 00:32:43,178] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 00:32:43,198] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 00:34:44,986] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 00:34:45,130] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 00:34:45,130] [INFO]: [STAGE] full rank start
[2026-01-18 00:34:45,362] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 00:34:45,363] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 00:34:45,364] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 00:34:45,366] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 00:34:45,366] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 00:34:46,205] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 00:34:46,207] [INFO]: [STAGE] gates start
[2026-01-18 00:34:46,213] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 00:34:51,390] [INFO]: [SUMMARY] run_ts=2026-01-18T06:30:06Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 00:34:51,496] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 00:34:51,515] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 00:34:53,927] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 00:34:54,121] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 00:34:58,995] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 00:34:58,996] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T06:34:59.158352+00:00] END screener rc=0 secs=294.0
[2026-01-18T06:52:21.511746+00:00] START screener
[2026-01-18 00:52:22,269] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:52:22,273] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 00:52:22,276] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 00:52:22,590] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 00:52:22,590] [INFO]: [STAGE] fetch start
[2026-01-18 00:52:23,176] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 00:52:23,190] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 00:52:23,191] [INFO]: Asset sample: POCT:BATS, PRAA:NASDAQ, QID:ARCA, TSPA:ARCA, ALRG:ARCA
[2026-01-18 00:52:23,226] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 00:52:23,313] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 00:52:23,317] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 00:52:23,418] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 00:52:23,465] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,486] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,504] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,526] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,546] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,568] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,591] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,613] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,634] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 00:52:23,974] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 00:52:47,012] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 00:52:48,260] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 00:52:48,268] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 00:52:48,269] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 00:52:48,269] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 00:52:48,269] [INFO]: Fallback batches invoked: 1
[2026-01-18 00:52:48,269] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 00:52:50,628] [INFO]: [STAGE] fetch end (rows=364439, elapsed=28.04s)
[2026-01-18 00:52:50,628] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 00:52:53,014] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 00:52:54,837] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 00:52:54,899] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 00:52:55,360] [INFO]: [STAGE] coarse features start
[2026-01-18 00:54:56,381] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 00:54:56,382] [INFO]: [STAGE] coarse rank start
[2026-01-18 00:54:56,603] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 00:54:56,603] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 00:54:56,611] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 00:54:56,630] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 00:56:57,761] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 00:56:57,914] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 00:56:57,914] [INFO]: [STAGE] full rank start
[2026-01-18 00:56:58,150] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 00:56:58,150] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 00:56:58,151] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 00:56:58,153] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 00:56:58,154] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 00:56:58,627] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 00:56:58,629] [INFO]: [STAGE] gates start
[2026-01-18 00:56:58,635] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 00:57:03,710] [INFO]: [SUMMARY] run_ts=2026-01-18T06:52:22Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 00:57:03,821] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 00:57:03,842] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 00:57:06,260] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 00:57:06,463] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 00:57:11,490] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 00:57:11,490] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T06:57:11.642708+00:00] END screener rc=0 secs=290.1
[2026-01-18T07:02:34.362681+00:00] START screener
[2026-01-18 01:02:35,109] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 01:02:35,112] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 01:02:35,114] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 01:02:35,289] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 01:02:35,289] [INFO]: [STAGE] fetch start
[2026-01-18 01:02:35,881] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 01:02:35,895] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 01:02:35,896] [INFO]: Asset sample: POCT:BATS, PRAA:NASDAQ, QID:ARCA, TSPA:ARCA, ALRG:ARCA
[2026-01-18 01:02:35,930] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 01:02:36,020] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 01:02:36,025] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 01:02:36,131] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 01:02:36,177] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,198] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,217] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,238] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,259] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,279] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,302] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,324] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,349] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 01:02:36,665] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 01:02:59,938] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 01:03:01,132] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 01:03:01,140] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 01:03:01,140] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 01:03:01,140] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 01:03:01,140] [INFO]: Fallback batches invoked: 1
[2026-01-18 01:03:01,140] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 01:03:03,479] [INFO]: [STAGE] fetch end (rows=364439, elapsed=28.19s)
[2026-01-18 01:03:03,479] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 01:03:05,967] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 01:03:07,765] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 01:03:07,826] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 01:03:08,310] [INFO]: [STAGE] coarse features start
[2026-01-18 01:05:11,476] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 01:05:11,476] [INFO]: [STAGE] coarse rank start
[2026-01-18 01:05:11,701] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 01:05:11,701] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 01:05:11,709] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 01:05:11,729] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 01:07:13,545] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 01:07:13,687] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 01:07:13,687] [INFO]: [STAGE] full rank start
[2026-01-18 01:07:13,906] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 01:07:13,906] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 01:07:13,907] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 01:07:13,909] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 01:07:13,909] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 01:07:14,362] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 01:07:14,365] [INFO]: [STAGE] gates start
[2026-01-18 01:07:14,370] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 01:07:19,338] [INFO]: [SUMMARY] run_ts=2026-01-18T07:02:35Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 01:07:19,448] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 01:07:19,468] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 01:07:21,870] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 01:07:22,078] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 01:07:26,887] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 01:07:26,887] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T07:07:27.030703+00:00] END screener rc=0 secs=292.7
[2026-01-18T16:08:48.509523+00:00] START screener
[2026-01-18 10:08:49,376] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:08:49,380] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:08:49,390] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 10:08:49,627] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 10:08:49,627] [INFO]: [STAGE] fetch start
[2026-01-18 10:08:50,259] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 10:08:50,277] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 10:08:50,279] [INFO]: Asset sample: A:NYSE, AEE:NYSE, AIRT:NASDAQ, AISPW:NASDAQ, APT:AMEX
[2026-01-18 10:08:50,322] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 10:08:50,427] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 10:08:50,436] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 10:08:50,536] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 10:08:50,682] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.1s cache=hit
[2026-01-18 10:08:50,707] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,731] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,756] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,779] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,803] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,829] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,855] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 10:08:50,881] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 10:08:51,289] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 10:09:15,801] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 10:09:17,120] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 10:09:17,130] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 10:09:17,130] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 10:09:17,130] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 10:09:17,130] [INFO]: Fallback batches invoked: 1
[2026-01-18 10:09:17,130] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 10:09:19,759] [INFO]: [STAGE] fetch end (rows=364439, elapsed=30.13s)
[2026-01-18 10:09:19,760] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 10:09:22,143] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 10:09:24,001] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 10:09:24,073] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 10:09:24,546] [INFO]: [STAGE] coarse features start
[2026-01-18 10:11:40,267] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 10:11:40,267] [INFO]: [STAGE] coarse rank start
[2026-01-18 10:11:40,525] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 10:11:40,525] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 10:11:40,532] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 10:11:40,555] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 10:13:53,881] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 10:13:54,054] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 10:13:54,054] [INFO]: [STAGE] full rank start
[2026-01-18 10:13:54,325] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 10:13:54,325] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 10:13:54,326] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 10:13:54,328] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 10:13:54,328] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 10:13:55,203] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 10:13:55,206] [INFO]: [STAGE] gates start
[2026-01-18 10:13:55,213] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 10:14:01,136] [INFO]: [SUMMARY] run_ts=2026-01-18T16:08:49Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 10:14:01,245] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 10:14:01,266] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 10:14:03,843] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 10:14:04,118] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 10:14:09,110] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 10:14:09,111] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T16:14:09.289858+00:00] END screener rc=0 secs=320.8
[2026-01-18T16:20:57.768211+00:00] START screener
[2026-01-18 10:20:58,558] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:20:58,562] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:20:58,564] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 10:20:59,034] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 10:20:59,034] [INFO]: [STAGE] fetch start
[2026-01-18 10:21:00,127] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 10:21:00,140] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 10:21:00,141] [INFO]: Asset sample: BIOX:NASDAQ, ARKD:BATS, COWS:NASDAQ, HDEF:ARCA, FBRT:NYSE
[2026-01-18 10:21:00,175] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 10:21:00,266] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 10:21:00,270] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 10:21:00,405] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 10:21:00,452] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,473] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,493] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,515] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,537] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,559] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,581] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,604] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,628] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 10:21:00,948] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 10:21:24,858] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 10:21:26,170] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 10:21:26,178] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 10:21:26,178] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 10:21:26,178] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 10:21:26,178] [INFO]: Fallback batches invoked: 1
[2026-01-18 10:21:26,178] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 10:21:28,559] [INFO]: [STAGE] fetch end (rows=364439, elapsed=29.52s)
[2026-01-18 10:21:28,559] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 10:21:30,947] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 10:21:32,780] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 10:21:32,841] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 10:21:33,290] [INFO]: [STAGE] coarse features start
[2026-01-18 10:23:37,989] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 10:23:37,989] [INFO]: [STAGE] coarse rank start
[2026-01-18 10:23:38,221] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 10:23:38,221] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 10:23:38,230] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 10:23:38,251] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 10:25:45,870] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 10:25:46,004] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 10:25:46,004] [INFO]: [STAGE] full rank start
[2026-01-18 10:25:46,222] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 10:25:46,222] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 10:25:46,223] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 10:25:46,225] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 10:25:46,225] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 10:25:46,717] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 10:25:46,720] [INFO]: [STAGE] gates start
[2026-01-18 10:25:46,725] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 10:25:52,220] [INFO]: [SUMMARY] run_ts=2026-01-18T16:20:59Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 10:25:52,325] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 10:25:52,345] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 10:25:54,818] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 10:25:55,014] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 10:25:59,822] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 10:25:59,822] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T16:25:59.979968+00:00] END screener rc=0 secs=302.2
[2026-01-18T16:34:07.938357+00:00] START screener
[2026-01-18 10:34:08,702] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:34:08,705] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:34:08,707] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 10:34:08,950] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 10:34:08,950] [INFO]: [STAGE] fetch start
[2026-01-18 10:34:09,860] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 10:34:09,879] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 10:34:09,880] [INFO]: Asset sample: AES:NYSE, A:NYSE, CAL:NYSE, AEE:NYSE, IAC:NASDAQ
[2026-01-18 10:34:09,919] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 10:34:10,012] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 10:34:10,017] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 10:34:10,119] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 10:34:10,171] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.1s cache=hit
[2026-01-18 10:34:10,192] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,214] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,236] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,256] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,278] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,300] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,324] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,348] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 10:34:10,673] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 10:34:34,380] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 10:34:35,651] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 10:34:35,658] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 10:34:35,658] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 10:34:35,658] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 10:34:35,659] [INFO]: Fallback batches invoked: 1
[2026-01-18 10:34:35,659] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 10:34:38,180] [INFO]: [STAGE] fetch end (rows=364439, elapsed=29.23s)
[2026-01-18 10:34:38,180] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 10:34:40,571] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 10:34:42,461] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 10:34:42,521] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 10:34:42,988] [INFO]: [STAGE] coarse features start
[2026-01-18 10:37:00,879] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 10:37:00,879] [INFO]: [STAGE] coarse rank start
[2026-01-18 10:37:01,101] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 10:37:01,101] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 10:37:01,109] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 10:37:01,129] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 10:39:03,999] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 10:39:04,146] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 10:39:04,147] [INFO]: [STAGE] full rank start
[2026-01-18 10:39:04,381] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 10:39:04,381] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 10:39:04,383] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 10:39:04,385] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 10:39:04,385] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 10:39:04,836] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 10:39:04,838] [INFO]: [STAGE] gates start
[2026-01-18 10:39:04,844] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 10:39:10,069] [INFO]: [SUMMARY] run_ts=2026-01-18T16:34:08Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 10:39:10,170] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 10:39:10,190] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 10:39:12,573] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 10:39:12,755] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 10:39:17,536] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 10:39:17,537] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T16:39:17.674926+00:00] END screener rc=0 secs=309.7
[2026-01-18T16:54:43.419617+00:00] START screener
[2026-01-18 10:54:44,188] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:54:44,192] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 10:54:44,194] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 10:54:44,406] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 10:54:44,406] [INFO]: [STAGE] fetch start
[2026-01-18 10:54:44,981] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 10:54:44,995] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 10:54:44,996] [INFO]: Asset sample: ALISU:NASDAQ, ALISR:NASDAQ, HAYW:NYSE, HAWX:ARCA, HAS:NASDAQ
[2026-01-18 10:54:45,033] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 10:54:45,124] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 10:54:45,128] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 10:54:45,229] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 10:54:45,274] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,297] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,317] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,338] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,358] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,379] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,401] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,424] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,447] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 10:54:45,769] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 10:55:09,246] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 10:55:11,858] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 10:55:11,866] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 10:55:11,866] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 10:55:11,866] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 10:55:11,866] [INFO]: Fallback batches invoked: 1
[2026-01-18 10:55:11,866] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 10:55:14,154] [INFO]: [STAGE] fetch end (rows=364439, elapsed=29.75s)
[2026-01-18 10:55:14,154] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 10:55:16,542] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 10:55:18,309] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 10:55:18,367] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 10:55:18,809] [INFO]: [STAGE] coarse features start
[2026-01-18 10:57:25,932] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 10:57:25,932] [INFO]: [STAGE] coarse rank start
[2026-01-18 10:57:26,156] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 10:57:26,156] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 10:57:26,163] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 10:57:26,183] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 10:59:35,802] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 10:59:35,972] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 10:59:35,972] [INFO]: [STAGE] full rank start
[2026-01-18 10:59:36,226] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 10:59:36,226] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 10:59:36,227] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 10:59:36,230] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 10:59:36,230] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 10:59:37,000] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 10:59:37,002] [INFO]: [STAGE] gates start
[2026-01-18 10:59:37,007] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 10:59:42,442] [INFO]: [SUMMARY] run_ts=2026-01-18T16:54:44Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 10:59:42,551] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 10:59:42,572] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 10:59:44,952] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 10:59:45,150] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 10:59:49,939] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 10:59:49,939] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
 Bars window attempts: [750] -> used=750
[2026-01-18 10:57:43,051] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 10:57:43,052] [INFO]: Fallback batches invoked: 1
[2026-01-18 10:57:43,052] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 10:57:45,901] [INFO]: [STAGE] fetch end (rows=364439, elapsed=29.45s)
[2026-01-18 10:57:45,902] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 10:57:48,282] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 10:57:50,316] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 10:57:50,379] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 10:57:50,846] [INFO]: [STAGE] coarse features start
[2026-01-18 10:59:59,279] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 10:59:59,279] [INFO]: [STAGE] coarse rank start
[2026-01-18 10:59:59,514] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 10:59:59,514] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 10:59:59,522] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 10:59:59,543] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 11:02:05,297] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 11:02:05,436] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 11:02:05,437] [INFO]: [STAGE] full rank start
[2026-01-18 11:02:05,662] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 11:02:05,662] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 11:02:05,663] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 11:02:05,665] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 11:02:05,665] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 11:02:06,158] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 11:02:06,160] [INFO]: [STAGE] gates start
[2026-01-18 11:02:06,167] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 11:02:11,314] [INFO]: [SUMMARY] run_ts=2026-01-18T16:57:16Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 11:02:11,414] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 11:02:11,435] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 11:02:14,104] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 11:02:14,303] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 11:02:22,547] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 11:02:22,547] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T17:02:22.692461+00:00] END screener rc=0 secs=307.3
[2026-01-18T17:14:16.912828+00:00] START screener
[2026-01-18 11:14:17,674] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 11:14:17,678] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 11:14:17,690] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 11:14:17,919] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 11:14:17,919] [INFO]: [STAGE] fetch start
[2026-01-18 11:14:18,609] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 11:14:18,623] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 11:14:18,625] [INFO]: Asset sample: ALISU:NASDAQ, ALISR:NASDAQ, HAYW:NYSE, HAWX:ARCA, HAS:NASDAQ
[2026-01-18 11:14:18,669] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 11:14:18,777] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 11:14:18,786] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 11:14:18,889] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 11:14:19,026] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.1s cache=hit
[2026-01-18 11:14:19,049] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,072] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,096] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,120] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,144] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,169] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,193] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,219] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 11:14:19,582] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 11:14:44,508] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 11:14:45,907] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 11:14:45,916] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 11:14:45,916] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 11:14:45,916] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 11:14:45,916] [INFO]: Fallback batches invoked: 1
[2026-01-18 11:14:45,917] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 11:14:48,519] [INFO]: [STAGE] fetch end (rows=364439, elapsed=30.60s)
[2026-01-18 11:14:48,519] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 11:14:50,941] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 11:14:52,850] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 11:14:52,943] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 11:14:53,439] [INFO]: [STAGE] coarse features start
[2026-01-18 11:16:57,589] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 11:16:57,589] [INFO]: [STAGE] coarse rank start
[2026-01-18 11:16:57,848] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 11:16:57,848] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 11:16:57,855] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 11:16:57,880] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 11:18:56,805] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 11:18:56,932] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 11:18:56,932] [INFO]: [STAGE] full rank start
[2026-01-18 11:18:57,135] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 11:18:57,136] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 11:18:57,136] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 11:18:57,138] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 11:18:57,139] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 11:18:58,138] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 11:18:58,140] [INFO]: [STAGE] gates start
[2026-01-18 11:18:58,145] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 11:19:02,948] [INFO]: [SUMMARY] run_ts=2026-01-18T17:14:17Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 11:19:03,053] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 11:19:03,071] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 11:19:05,522] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 11:19:05,737] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 11:19:10,619] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 11:19:10,619] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T17:19:10.792418+00:00] END screener rc=0 secs=293.9
[2026-01-18T17:27:57.437451+00:00] START screener
[2026-01-18 11:27:58,107] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 11:27:58,110] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 11:27:58,113] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 11:27:58,291] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-15 source=cli
[2026-01-18 11:27:58,292] [INFO]: [STAGE] fetch start
[2026-01-18 11:27:58,895] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 11:27:58,909] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 11:27:58,911] [INFO]: Asset sample: ALISU:NASDAQ, ALISR:NASDAQ, HAYW:NYSE, HAWX:ARCA, HAS:NASDAQ
[2026-01-18 11:27:58,943] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 11:27:59,030] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 11:27:59,034] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 11:27:59,133] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 11:27:59,187] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.1s cache=hit
[2026-01-18 11:27:59,207] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,227] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,249] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,270] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,292] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,316] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,337] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,360] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 11:27:59,662] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 11:28:23,912] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 11:28:25,265] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 11:28:25,273] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 11:28:25,273] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 11:28:25,273] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 11:28:25,273] [INFO]: Fallback batches invoked: 1
[2026-01-18 11:28:25,273] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 11:28:27,543] [INFO]: [STAGE] fetch end (rows=364439, elapsed=29.25s)
[2026-01-18 11:28:27,543] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 11:28:29,931] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 11:28:31,683] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 11:28:31,741] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 11:28:32,189] [INFO]: [STAGE] coarse features start
[2026-01-18 11:30:27,720] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 11:30:27,720] [INFO]: [STAGE] coarse rank start
[2026-01-18 11:30:27,937] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 11:30:27,937] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 11:30:27,944] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 11:30:27,963] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 11:32:25,536] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 11:32:25,668] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 11:32:25,668] [INFO]: [STAGE] full rank start
[2026-01-18 11:32:25,879] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 11:32:25,879] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 11:32:25,880] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 11:32:25,882] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 11:32:25,882] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 11:32:26,373] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 11:32:26,375] [INFO]: [STAGE] gates start
[2026-01-18 11:32:26,380] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 11:32:31,282] [INFO]: [SUMMARY] run_ts=2026-01-18T17:27:58Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 11:32:31,385] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 11:32:31,405] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 11:32:33,842] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 11:32:34,013] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 11:32:39,008] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 11:32:39,009] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T17:32:39.176292+00:00] END screener rc=0 secs=281.7
[2026-01-18T18:01:20.326264+00:00] START screener
[2026-01-18 12:01:21,061] [INFO]: Script started
[INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 12:01:21,065] [INFO]: [INFO] ENV_LOADED files=["C:\\Users\\RasPa\\JBravoGit\\JBRAVO_Screener\\.env"]
[2026-01-18 12:01:21,067] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-18 12:01:21,267] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-16 source=cli
[2026-01-18 12:01:21,267] [INFO]: [STAGE] fetch start
[2026-01-18 12:01:21,896] [INFO]: Asset meta ready: 12088 symbols (tradable US equities)
[2026-01-18 12:01:21,908] [INFO]: Asset metrics: total=13154 tradable_equities=12354 after_filters=12088
[2026-01-18 12:01:21,909] [INFO]: Asset sample: A:NYSE, AEE:NYSE, AIRT:NASDAQ, AISPW:NASDAQ, APT:AMEX
[2026-01-18 12:01:21,943] [INFO]: Universe sample size: 5875 (of 12088 tradable equities)
[2026-01-18 12:01:22,032] [INFO]: Universe hygiene filtered 5875 -> 4934 symbols
[2026-01-18 12:01:22,037] [INFO]: Universe prefix counts: {'A': 48, 'C': 39, 'S': 38, 'N': 30, 'M': 25, 'G': 22, 'P': 21, 'B': 21, 'I': 21, 'E': 20, 'F': 19, 'T': 18, 'V': 17, 'L': 16, 'H': 16, 'R': 12, 'D': 12, 'W': 11, 'O': 11, 'U': 11, 'K': 6, 'Z': 6, 'X': 5, 'J': 3, 'Y': 2}
[2026-01-18 12:01:22,136] [INFO]: Requesting 750 trading days ending 2026-01-16 (2023-01-20T00:00:00Z -> 2026-01-16T23:59:59Z)
[2026-01-18 12:01:22,182] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=3 rows=~20951 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,203] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32311 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,222] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~30383 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,244] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,265] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31569 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,287] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~32381 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,309] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34839 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,332] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35132 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,354] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~35590 elapsed=0.0s cache=hit
[2026-01-18 12:01:22,708] [INFO]: [BARS_ACCEPT] accepted=400 dropped_missing=50
[2026-01-18 12:01:48,422] [INFO]: [BARS_RETRY] retried=411 recovered=386
[2026-01-18 12:01:49,895] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-18 12:01:49,904] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=35 rows=285942 symbols_with_bars=391
[2026-01-18 12:01:49,904] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-18 12:01:49,904] [INFO]: Symbols without bars (sample): ['VOYG', 'CBC', 'OTH', 'CRAQ', 'GLIBK', 'ETOR', 'FCRS', 'LCCCR', 'GTERR', 'THH']
[2026-01-18 12:01:49,904] [INFO]: Fallback batches invoked: 1
[2026-01-18 12:01:49,904] [INFO]: Symbols dropped for insufficient history: 29
C:\Users\RasPa\JBravoGit\JBRAVO_Screener\scripts\screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-18 12:01:52,329] [INFO]: [STAGE] fetch end (rows=364439, elapsed=31.06s)
[2026-01-18 12:01:52,329] [INFO]: [BARS_DIAG] feed=iex requested=886 with_bars=400 missing=486 examples=[VOYG,CBC,OTH,CRAQ,GLIBK,ETOR,FCRS,LCCCR,GTERR,THH]
[2026-01-18 12:01:54,745] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-18 12:01:56,566] [INFO]: [INFO] DAILY_BARS_EXPORTED path=C:\Users\RasPa\JBravoGit\JBRAVO_Screener\data\daily_bars.csv rows=364439 symbols=500
[2026-01-18 12:01:56,624] [INFO]: [INFO] SENTIMENT enabled=False url_set=False weight=0.000 min=-999.000
[2026-01-18 12:01:57,084] [INFO]: [STAGE] coarse features start
[2026-01-18 12:03:59,796] [INFO]: [STAGE] coarse features end (rows=324497)
[2026-01-18 12:03:59,796] [INFO]: [STAGE] coarse rank start
[2026-01-18 12:04:00,021] [INFO]: [INFO] Coarse rank boundary rows_in=445 score_non_null=445 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-18 12:04:00,021] [INFO]: [STAGE] coarse rank end (rows=445)
[2026-01-18 12:04:00,028] [INFO]: [STAGE] shortlist written: data\tmp\shortlist.csv (rows=445)
[2026-01-18 12:04:00,050] [INFO]: [STAGE] full features start (shortlist=445)
[2026-01-18 12:06:02,291] [INFO]: [STAGE] full features end (rows=324497)
[2026-01-18 12:06:02,434] [INFO]: [STAGE] finalize candidates pruned rows=324497 -> 316259
[2026-01-18 12:06:02,434] [INFO]: [STAGE] full rank start
[2026-01-18 12:06:02,656] [INFO]: [STAGE] full rank end (rows=445)
[2026-01-18 12:06:02,656] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=445 cols_has_symbol=True cache_dir=data\cache\sentiment run_date=2026-01-18
[2026-01-18 12:06:02,657] [INFO]: [INFO] SENTIMENT_FETCH skipped reason=disabled
[2026-01-18 12:06:02,658] [INFO]: [STAGE] quality filters pruned rows=445 -> 127
[2026-01-18 12:06:02,659] [INFO]: Rank model not found at data\models\rank_model.joblib; skipping ML ranking
[2026-01-18 12:06:03,122] [INFO]: [INFO] ML_RANK weight=0.30 rows=127 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5235 model=data\models\rank_model.joblib
[2026-01-18 12:06:03,124] [INFO]: [STAGE] gates start
[2026-01-18 12:06:03,130] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-18 12:06:08,237] [INFO]: [SUMMARY] run_ts=2026-01-18T18:01:21Z mode=screener symbols_in=7745 with_bars=445 coarse_rows=445 shortlist_rows=445 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-18 12:06:08,316] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-18 12:06:08,326] [INFO]: [STAGE] predictions written: data\predictions\2026-01-18.csv (top_n=127)
[2026-01-18 12:06:08,346] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-18 12:06:10,769] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-18 12:06:10,994] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-18 12:06:18,770] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-18 12:06:18,771] [INFO]: Screener complete: 7745 symbols examined, 6 candidates.
[2026-01-18T18:06:18.918685+00:00] END screener rc=0 secs=298.6
[2026-01-22T15:20:55.393969+00:00] START screener
[2026-01-22 15:20:56,524] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 15:20:56,529] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 15:20:56,536] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 15:20:56,624] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 15:20:56,625] [INFO]: [STAGE] fetch start
[2026-01-22 15:20:57,136] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 15:20:57,179] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 15:20:57,182] [INFO]: Asset sample: BAC.PRS:NYSE, CGUI:ARCA, BAC.PRO:NYSE, BAC.PRM:NYSE, NETG:NASDAQ
[2026-01-22 15:20:57,227] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 15:20:57,491] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 15:20:57,508] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 15:20:57,616] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 15:20:57,884] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.3s cache=hit
[2026-01-22 15:20:57,934] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.0s cache=hit
[2026-01-22 15:20:57,997] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-22 15:20:58,047] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 15:20:58,107] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 15:20:58,190] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 15:20:58,241] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 15:20:58,295] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 15:20:58,347] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.1s cache=hit
[2026-01-22 15:20:59,114] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 15:21:13,596] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 15:21:15,106] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 15:21:15,116] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 15:21:15,116] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 15:21:15,116] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 15:21:15,116] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 15:21:15,117] [INFO]: Fallback batches invoked: 1
[2026-01-22 15:21:15,117] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 15:21:20,989] [INFO]: [STAGE] fetch end (rows=361183, elapsed=24.36s)
[2026-01-22 15:21:20,989] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 15:21:21,061] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 15:21:26,107] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 15:21:26,256] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 15:21:27,239] [INFO]: [STAGE] coarse features start
[2026-01-22 15:28:13,121] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 15:28:13,122] [INFO]: [STAGE] coarse rank start
[2026-01-22 15:28:13,582] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 15:28:13,582] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 15:28:13,605] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 15:28:13,645] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22 15:35:12,859] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 15:35:13,081] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 15:35:13,081] [INFO]: [STAGE] full rank start
[2026-01-22 15:35:13,481] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 15:35:13,481] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 15:35:13,484] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 15:35:13,500] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x79a1cde982e0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 15:35:13,502] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x79a1cde9bcd0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 15:35:13,504] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x79a1cde98dc0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 15:35:13,505] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 15:35:19,450] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 15:35:19,450] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 15:35:19,450] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=5.966
[2026-01-22 15:35:19,471] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 15:35:19,472] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 15:35:21,628] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 15:35:21,634] [INFO]: [STAGE] gates start
[2026-01-22 15:35:21,650] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 15:35:40,542] [INFO]: [SUMMARY] run_ts=2026-01-22T15:20:56Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 15:35:40,699] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 15:35:40,768] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 15:35:40,850] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 15:35:40,888] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 15:35:40,892] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 15:35:40,905] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 15:35:40,955] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 15:35:40,955] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T15:35:41.256910+00:00] END screener rc=0 secs=885.9
[2026-01-22T16:31:01.366414+00:00] START screener
[2026-01-22 16:31:02,996] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 16:31:03,004] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 16:31:03,011] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 16:31:03,037] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 16:31:03,037] [INFO]: [STAGE] fetch start
[2026-01-22 16:31:03,680] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 16:31:03,732] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 16:31:03,735] [INFO]: Asset sample: NEWTP:NASDAQ, ASBP:NASDAQ, PBJA:BATS, ASB.PRE:NYSE, NEWTI:NASDAQ
[2026-01-22 16:31:03,814] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 16:31:04,174] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 16:31:04,187] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 16:31:04,360] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 16:31:04,457] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.1s cache=hit
[2026-01-22 16:31:04,498] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.0s cache=hit
[2026-01-22 16:31:04,540] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-22 16:31:04,579] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 16:31:04,623] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.0s cache=hit
[2026-01-22 16:31:04,695] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 16:31:04,762] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 16:31:04,826] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 16:31:04,897] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.1s cache=hit
[2026-01-22 16:31:05,652] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 16:31:20,327] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 16:31:21,443] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 16:31:21,451] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 16:31:21,451] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 16:31:21,452] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 16:31:21,452] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 16:31:21,452] [INFO]: Fallback batches invoked: 1
[2026-01-22 16:31:21,452] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 16:31:27,013] [INFO]: [STAGE] fetch end (rows=361183, elapsed=23.98s)
[2026-01-22 16:31:27,013] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 16:31:27,035] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 16:31:31,951] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 16:31:32,079] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 16:31:33,086] [INFO]: [STAGE] coarse features start
[2026-01-22 16:37:51,209] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 16:37:51,209] [INFO]: [STAGE] coarse rank start
[2026-01-22 16:37:51,590] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 16:37:51,591] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 16:37:51,612] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 16:37:51,648] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22T16:40:09.293381+00:00] START screener
[2026-01-22 16:40:11,131] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 16:40:11,142] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 16:40:11,149] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 16:40:11,176] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 16:40:11,177] [INFO]: [STAGE] fetch start
[2026-01-22 16:40:11,731] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 16:40:11,790] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 16:40:11,793] [INFO]: Asset sample: NEWTP:NASDAQ, ASBP:NASDAQ, PBJA:BATS, ASB.PRE:NYSE, NEWTI:NASDAQ
[2026-01-22 16:40:11,879] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 16:40:12,244] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 16:40:12,257] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 16:40:12,452] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 16:40:12,577] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.1s cache=hit
[2026-01-22 16:40:12,640] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.1s cache=hit
[2026-01-22 16:40:12,683] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-22 16:40:12,723] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 16:40:12,799] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 16:40:12,913] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 16:40:12,988] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 16:40:13,063] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 16:40:13,121] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.1s cache=hit
[2026-01-22 16:40:14,185] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 16:40:23,727] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 16:40:24,520] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 16:40:24,528] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 16:40:24,529] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 16:40:24,529] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 16:40:24,529] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 16:40:24,529] [INFO]: Fallback batches invoked: 1
[2026-01-22 16:40:24,529] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 16:40:32,032] [INFO]: [STAGE] fetch end (rows=361183, elapsed=20.86s)
[2026-01-22 16:40:32,032] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 16:40:32,053] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 16:40:37,659] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 16:40:37,794] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 16:40:38,865] [INFO]: [STAGE] coarse features start
[2026-01-22 16:45:38,662] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 16:45:38,929] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 16:45:38,929] [INFO]: [STAGE] full rank start
[2026-01-22 16:45:39,425] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 16:45:39,425] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 16:45:39,428] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 16:45:39,443] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x767a9fbc0160>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 16:45:39,450] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x767a9fbc24d0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 16:45:39,453] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x767a9fbc3ca0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 16:45:39,456] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 16:45:45,816] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 16:45:45,816] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 16:45:45,816] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=6.388
[2026-01-22 16:45:45,841] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 16:45:45,843] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 16:45:46,720] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 16:45:46,725] [INFO]: [STAGE] gates start
[2026-01-22 16:45:46,738] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 16:46:01,172] [INFO]: [SUMMARY] run_ts=2026-01-22T16:31:03Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 16:46:01,350] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 16:46:01,453] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 16:46:01,555] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 16:46:01,597] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 16:46:01,601] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 16:46:01,615] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 16:46:01,666] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 16:46:01,666] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T16:46:02.000286+00:00] END screener rc=0 secs=900.6
[2026-01-22 16:48:20,745] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 16:48:20,746] [INFO]: [STAGE] coarse rank start
[2026-01-22 16:48:21,180] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 16:48:21,181] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 16:48:21,200] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 16:48:21,241] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22 16:54:40,925] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 16:54:41,166] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 16:54:41,166] [INFO]: [STAGE] full rank start
[2026-01-22 16:54:41,563] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 16:54:41,563] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 16:54:41,566] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 16:54:41,576] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f3ef87645e0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 16:54:41,578] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f3ef8766f80>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 16:54:41,580] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f3ef8767a30>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 16:54:41,582] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 16:54:47,582] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 16:54:47,582] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 16:54:47,582] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=6.016
[2026-01-22 16:54:47,605] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 16:54:47,606] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 16:54:48,389] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 16:54:48,396] [INFO]: [STAGE] gates start
[2026-01-22 16:54:48,420] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 16:55:02,813] [INFO]: [SUMMARY] run_ts=2026-01-22T16:40:11Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 16:55:02,956] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 16:55:03,014] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 16:55:03,088] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 16:55:03,125] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 16:55:03,128] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 16:55:03,143] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 16:55:03,195] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 16:55:03,196] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T16:55:03.468561+00:00] END screener rc=0 secs=894.2
[2026-01-22T17:01:17.766917+00:00] START screener
[2026-01-22 17:01:18,914] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:01:18,919] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:01:18,923] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 17:01:19,099] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 17:01:19,099] [INFO]: [STAGE] fetch start
[2026-01-22 17:01:19,594] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 17:01:19,632] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 17:01:19,634] [INFO]: Asset sample: BALI:BATS, ICU:NASDAQ, NETG:NASDAQ, ASBP:NASDAQ, PBJA:BATS
[2026-01-22 17:01:19,674] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 17:01:19,862] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 17:01:19,871] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 17:01:19,974] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 17:01:20,049] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.1s cache=hit
[2026-01-22 17:01:20,089] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.0s cache=hit
[2026-01-22 17:01:20,136] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-22 17:01:20,176] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 17:01:20,221] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.0s cache=hit
[2026-01-22 17:01:20,290] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 17:01:20,335] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.0s cache=hit
[2026-01-22 17:01:20,375] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.0s cache=hit
[2026-01-22 17:01:20,420] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.0s cache=hit
[2026-01-22 17:01:21,132] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 17:01:33,420] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 17:01:34,729] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 17:01:34,737] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 17:01:34,737] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 17:01:34,738] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 17:01:34,738] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 17:01:34,738] [INFO]: Fallback batches invoked: 1
[2026-01-22 17:01:34,738] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 17:01:40,362] [INFO]: [STAGE] fetch end (rows=361183, elapsed=21.26s)
[2026-01-22 17:01:40,362] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 17:01:40,386] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 17:01:46,331] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 17:01:46,465] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 17:01:47,426] [INFO]: [STAGE] coarse features start
[2026-01-22T17:09:12.459190+00:00] START screener
[2026-01-22 17:09:13,645] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:09:13,651] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:09:13,656] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 17:09:13,706] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 17:09:13,706] [INFO]: [STAGE] fetch start
[2026-01-22 17:09:14,478] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 17:09:14,523] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 17:09:14,526] [INFO]: Asset sample: BALI:BATS, ICU:NASDAQ, NETG:NASDAQ, ASBP:NASDAQ, PBJA:BATS
[2026-01-22 17:09:14,577] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 17:09:14,798] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 17:09:14,813] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 17:09:15,004] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 17:09:15,249] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.2s cache=hit
[2026-01-22 17:09:15,302] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,355] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,409] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,469] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,563] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,617] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,671] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 17:09:15,726] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.1s cache=hit
[2026-01-22 17:09:16,544] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 17:09:26,948] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 17:09:28,965] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 17:09:28,974] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 17:09:28,974] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 17:09:28,974] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 17:09:28,974] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 17:09:28,974] [INFO]: Fallback batches invoked: 1
[2026-01-22 17:09:28,974] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 17:09:35,074] [INFO]: [STAGE] fetch end (rows=361183, elapsed=21.37s)
[2026-01-22 17:09:35,075] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 17:09:35,139] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 17:09:40,166] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 17:09:40,309] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 17:09:41,295] [INFO]: [STAGE] coarse features start
[2026-01-22T17:10:16.173117+00:00] START screener
[2026-01-22 17:10:17,405] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:10:17,413] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:10:17,419] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 17:10:17,464] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 17:10:17,464] [INFO]: [STAGE] fetch start
[2026-01-22 17:10:19,438] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 17:10:19,485] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 17:10:19,488] [INFO]: Asset sample: BALI:BATS, ICU:NASDAQ, NETG:NASDAQ, ASBP:NASDAQ, PBJA:BATS
[2026-01-22 17:10:19,540] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 17:10:19,761] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 17:10:19,774] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 17:10:20,552] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 17:10:20,732] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.2s cache=hit
[2026-01-22 17:10:20,782] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.1s cache=hit
[2026-01-22 17:10:20,834] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-22 17:10:20,885] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.1s cache=hit
[2026-01-22 17:10:20,941] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 17:10:21,035] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 17:10:21,094] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 17:10:21,143] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.0s cache=hit
[2026-01-22 17:10:21,194] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.0s cache=hit
[2026-01-22 17:10:22,024] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 17:10:34,917] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 17:10:36,428] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 17:10:36,439] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 17:10:36,439] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 17:10:36,439] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 17:10:36,440] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 17:10:36,440] [INFO]: Fallback batches invoked: 1
[2026-01-22 17:10:36,440] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 17:10:42,114] [INFO]: [STAGE] fetch end (rows=361183, elapsed=24.65s)
[2026-01-22 17:10:42,114] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 17:10:42,152] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 17:10:47,615] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 17:10:47,750] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 17:10:48,782] [INFO]: [STAGE] coarse features start
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2026-01-22 17:18:00,317] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 17:18:00,318] [INFO]: [STAGE] coarse rank start
[2026-01-22 17:18:00,803] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 17:18:00,803] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 17:18:00,827] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 17:18:00,870] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22 17:23:42,034] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 17:23:42,326] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 17:23:42,326] [INFO]: [STAGE] full rank start
[2026-01-22 17:23:42,811] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 17:23:42,811] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 17:23:42,815] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 17:23:42,828] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x747ca84586a0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 17:23:42,831] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x747ca845ace0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 17:23:42,834] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x747ca84592d0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 17:23:42,838] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 17:23:48,804] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 17:23:48,804] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 17:23:48,805] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=5.989
[2026-01-22 17:23:48,828] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 17:23:48,829] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 17:23:50,772] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 17:23:50,778] [INFO]: [STAGE] gates start
[2026-01-22 17:23:50,794] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 17:24:12,197] [INFO]: [SUMMARY] run_ts=2026-01-22T17:09:13Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 17:24:12,379] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 17:24:12,446] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 17:24:12,513] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 17:24:12,553] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 17:24:12,556] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 17:24:12,572] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 17:24:12,629] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 17:24:12,630] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T17:24:13.013614+00:00] END screener rc=0 secs=900.6
[2026-01-22 17:25:53,823] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 17:25:54,086] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 17:25:54,086] [INFO]: [STAGE] full rank start
[2026-01-22 17:25:54,560] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 17:25:54,560] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 17:25:54,563] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 17:25:54,577] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x704773b293f0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 17:25:54,580] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x704773b29900>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 17:25:54,582] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x704773b28130>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 17:25:54,584] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 17:26:00,564] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 17:26:00,564] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 17:26:00,564] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=6.001
[2026-01-22 17:26:00,591] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 17:26:00,593] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 17:26:02,234] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 17:26:02,240] [INFO]: [STAGE] gates start
[2026-01-22 17:26:02,259] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 17:26:24,148] [INFO]: [SUMMARY] run_ts=2026-01-22T17:10:17Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 17:26:24,321] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 17:26:24,387] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 17:26:24,454] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 17:26:24,486] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 17:26:24,489] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 17:26:24,502] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 17:26:24,550] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 17:26:24,551] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T17:26:24.889374+00:00] END screener rc=0 secs=968.7
[2026-01-22T17:50:36.246281+00:00] START screener
[2026-01-22 17:50:37,706] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:50:37,711] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:50:37,717] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 17:50:37,741] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 17:50:37,741] [INFO]: [STAGE] fetch start
[2026-01-22 17:50:38,398] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 17:50:38,448] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 17:50:38,453] [INFO]: Asset sample: XLU:ARCA, XLRE:ARCA, XLP:ARCA, XLI:ARCA, XLG:ARCA
[2026-01-22 17:50:38,542] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 17:50:38,912] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 17:50:38,932] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 17:50:39,099] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 17:50:39,294] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.2s cache=hit
[2026-01-22 17:50:39,378] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,459] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,533] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,623] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,764] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,817] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,882] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 17:50:39,964] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.1s cache=hit
[2026-01-22 17:50:40,990] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 17:50:50,469] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 17:50:51,858] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 17:50:51,867] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 17:50:51,867] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 17:50:51,867] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 17:50:51,867] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 17:50:51,867] [INFO]: Fallback batches invoked: 1
[2026-01-22 17:50:51,867] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 17:50:58,109] [INFO]: [STAGE] fetch end (rows=361183, elapsed=20.37s)
[2026-01-22 17:50:58,109] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 17:50:58,160] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 17:51:03,840] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 17:51:04,032] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 17:51:05,357] [INFO]: [STAGE] coarse features start
[2026-01-22 17:58:14,644] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 17:58:14,645] [INFO]: [STAGE] coarse rank start
[2026-01-22 17:58:15,090] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 17:58:15,091] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 17:58:15,112] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 17:58:15,166] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22T17:59:32.285972+00:00] START screener
[2026-01-22 17:59:33,458] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:59:33,463] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 17:59:33,467] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 17:59:33,670] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 17:59:33,670] [INFO]: [STAGE] fetch start
[2026-01-22 17:59:34,188] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 17:59:34,226] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 17:59:34,228] [INFO]: Asset sample: XLU:ARCA, XLRE:ARCA, XLP:ARCA, XLI:ARCA, XLG:ARCA
[2026-01-22 17:59:34,273] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 17:59:34,463] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 17:59:34,472] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 17:59:34,573] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 17:59:34,658] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.1s cache=hit
[2026-01-22 17:59:34,698] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.0s cache=hit
[2026-01-22 17:59:34,739] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-22 17:59:34,779] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 17:59:34,826] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.0s cache=hit
[2026-01-22 17:59:34,907] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 17:59:34,953] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.0s cache=hit
[2026-01-22 17:59:34,997] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.0s cache=hit
[2026-01-22 17:59:35,042] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.0s cache=hit
[2026-01-22 17:59:35,789] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 17:59:45,869] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 17:59:47,058] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 17:59:47,070] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 17:59:47,070] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 17:59:47,071] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 17:59:47,071] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 17:59:47,071] [INFO]: Fallback batches invoked: 1
[2026-01-22 17:59:47,071] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 17:59:52,391] [INFO]: [STAGE] fetch end (rows=361183, elapsed=18.72s)
[2026-01-22 17:59:52,391] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 17:59:52,413] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 17:59:57,642] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 17:59:57,771] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 17:59:58,788] [INFO]: [STAGE] coarse features start
[2026-01-22T18:18:02.078497+00:00] START screener
[2026-01-22 18:18:04,026] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 18:18:04,033] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 18:18:04,046] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 18:18:04,084] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 18:18:04,085] [INFO]: [STAGE] fetch start
[2026-01-22 18:18:04,780] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 18:18:04,840] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 18:18:04,843] [INFO]: Asset sample: LULG:NASDAQ, LUD:AMEX, LUCYW:NASDAQ, FBND:ARCA, LUCY:NASDAQ
[2026-01-22 18:18:04,918] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22T18:18:05.169690+00:00] START screener
[2026-01-22 18:18:05,207] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 18:18:05,222] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 18:18:05,443] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 18:18:05,650] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.2s cache=hit
[2026-01-22 18:18:05,697] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.0s cache=hit
[2026-01-22 18:18:05,754] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-22 18:18:05,802] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 18:18:05,876] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 18:18:05,961] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 18:18:06,027] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 18:18:06,085] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 18:18:06,131] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.0s cache=hit
[2026-01-22 18:18:06,579] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 18:18:06,587] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 18:18:06,599] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 18:18:06,622] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 18:18:06,622] [INFO]: [STAGE] fetch start
[2026-01-22 18:18:06,874] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 18:18:07,111] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 18:18:07,161] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 18:18:07,163] [INFO]: Asset sample: LULG:NASDAQ, LUD:AMEX, LUCYW:NASDAQ, FBND:ARCA, LUCY:NASDAQ
[2026-01-22 18:18:07,213] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 18:18:07,454] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 18:18:07,466] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 18:18:07,599] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 18:18:07,674] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.1s cache=hit
[2026-01-22 18:18:07,716] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.0s cache=hit
[2026-01-22 18:18:07,763] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.0s cache=hit
[2026-01-22 18:18:07,810] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.0s cache=hit
[2026-01-22 18:18:07,868] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 18:18:07,950] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 18:18:08,003] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 18:18:08,048] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.0s cache=hit
[2026-01-22 18:18:08,096] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.0s cache=hit
[2026-01-22 18:18:08,835] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 18:18:34,086] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 18:18:50,162] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 18:18:52,768] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 18:18:52,777] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 18:18:52,777] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 18:18:52,777] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 18:18:52,777] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 18:18:52,777] [INFO]: Fallback batches invoked: 1
[2026-01-22 18:18:52,777] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 18:18:57,677] [INFO]: [STAGE] fetch end (rows=361183, elapsed=53.59s)
[2026-01-22 18:18:57,677] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 18:18:57,719] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 18:18:58,449] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 18:18:58,461] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 18:18:58,461] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 18:18:58,461] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 18:18:58,461] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 18:18:58,461] [INFO]: Fallback batches invoked: 1
[2026-01-22 18:18:58,461] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 18:19:02,535] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 18:19:02,715] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 18:19:04,635] [INFO]: [STAGE] coarse features start
[2026-01-22 18:19:05,186] [INFO]: [STAGE] fetch end (rows=361183, elapsed=58.56s)
[2026-01-22 18:19:05,187] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 18:19:05,204] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 18:19:10,479] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 18:19:10,591] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 18:19:11,607] [INFO]: [STAGE] coarse features start
[2026-01-22 18:26:27,433] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 18:26:27,434] [INFO]: [STAGE] coarse rank start
[2026-01-22 18:26:27,896] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 18:26:27,896] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 18:26:27,917] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 18:26:27,955] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22 18:26:28,086] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 18:26:28,087] [INFO]: [STAGE] coarse rank start
[2026-01-22 18:26:28,470] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 18:26:28,470] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 18:26:28,492] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 18:26:28,529] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22 18:32:53,377] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 18:32:53,610] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 18:32:53,610] [INFO]: [STAGE] full rank start
[2026-01-22 18:32:53,991] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 18:32:53,991] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 18:32:53,994] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 18:32:54,006] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7a4d550ffdf0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 18:32:54,008] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7a4d550ffa30>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 18:32:54,010] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7a4d550fcc10>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 18:32:54,012] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 18:32:54,421] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 18:32:54,628] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 18:32:54,628] [INFO]: [STAGE] full rank start
[2026-01-22 18:32:55,034] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 18:32:55,034] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 18:32:55,037] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 18:32:59,495] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x71d3c8abb3d0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 18:32:59,498] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x71d3c8ab8bb0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 18:32:59,501] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x71d3c8aba530>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 18:32:59,503] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 18:33:05,274] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 18:33:05,274] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 18:33:05,275] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=11.280
[2026-01-22 18:33:05,302] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 18:33:05,303] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 18:33:07,508] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 18:33:07,513] [INFO]: [STAGE] gates start
[2026-01-22 18:33:07,527] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 18:33:10,677] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 18:33:10,677] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 18:33:10,677] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=15.640
[2026-01-22 18:33:10,702] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 18:33:10,704] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 18:33:11,629] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 18:33:11,639] [INFO]: [STAGE] gates start
[2026-01-22 18:33:11,659] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 18:33:24,240] [INFO]: [SUMMARY] run_ts=2026-01-22T18:18:06Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 18:33:24,392] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 18:33:24,451] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 18:33:24,518] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 18:33:24,553] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 18:33:24,557] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 18:33:24,570] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 18:33:24,622] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 18:33:24,622] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T18:33:24.915084+00:00] END screener rc=0 secs=919.8
[2026-01-22 18:33:28,859] [INFO]: [SUMMARY] run_ts=2026-01-22T18:18:04Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 18:33:29,004] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 18:33:29,065] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 18:33:29,142] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 18:33:29,247] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 18:33:29,254] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 18:33:29,267] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 18:33:29,319] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 18:33:29,319] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T18:33:29.599557+00:00] END screener rc=0 secs=927.5
[2026-01-22T19:15:58.542245+00:00] START screener
[2026-01-22 19:15:59,680] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 19:15:59,686] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 19:15:59,690] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 19:15:59,714] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 19:15:59,714] [INFO]: [STAGE] fetch start
[2026-01-22 19:16:00,103] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 19:16:00,143] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 19:16:00,146] [INFO]: Asset sample: BSJS:NASDAQ, PG:NYSE, BBIN:BATS, PFG:NASDAQ, OWLS:NASDAQ
[2026-01-22 19:16:00,179] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 19:16:00,413] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 19:16:00,437] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 19:16:00,567] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 19:16:00,571] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:02,117] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0001.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:02,117] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32045 elapsed=1.5s cache=miss
[2026-01-22 19:16:02,118] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:03,357] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0002.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:03,357] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32754 elapsed=1.2s cache=miss
[2026-01-22 19:16:03,358] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:04,562] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0003.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:04,562] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33460 elapsed=1.2s cache=miss
[2026-01-22 19:16:04,563] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:05,707] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0004.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:05,707] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=1.1s cache=miss
[2026-01-22 19:16:05,708] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:06,809] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0005.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:06,809] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31738 elapsed=1.1s cache=miss
[2026-01-22 19:16:06,810] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:07,896] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0006.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:07,896] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29377 elapsed=1.1s cache=miss
[2026-01-22 19:16:07,896] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:09,186] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0007.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:09,186] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=1.3s cache=miss
[2026-01-22 19:16:09,187] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:10,288] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0008.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:10,288] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33241 elapsed=1.1s cache=miss
[2026-01-22 19:16:10,289] [WARNING]: Failed to read cached batch data/cache/bars_1d_iex/2026-01-21/0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:11,505] [WARNING]: Failed to persist batch cache data/cache/bars_1d_iex/2026-01-21/0009.parquet: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.
A suitable version of pyarrow or fastparquet is required for parquet support.
Trying to import the above resulted in these errors:
 - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.
 - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.
[2026-01-22 19:16:11,505] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30633 elapsed=1.2s cache=miss
[2026-01-22 19:16:12,107] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-22 19:16:12,943] [INFO]: [BARS_RETRY] retried=41 recovered=0
[2026-01-22 19:16:13,607] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 19:16:13,623] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289421 symbols_with_bars=396
[2026-01-22 19:16:13,624] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 19:16:13,624] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 19:16:13,624] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 19:16:13,624] [INFO]: Fallback batches invoked: 1
[2026-01-22 19:16:13,624] [INFO]: Symbols dropped for insufficient history: 39
[2026-01-22 19:16:16,918] [INFO]: [STAGE] fetch end (rows=289637, elapsed=17.20s)
[2026-01-22 19:16:16,918] [INFO]: [BARS_DIAG] feed=iex requested=532 with_bars=409 missing=123 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 19:16:16,989] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 19:16:20,992] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=289637 symbols=410
[2026-01-22 19:16:21,110] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 19:16:21,725] [INFO]: [STAGE] coarse features start
[2026-01-22 19:21:00,762] [INFO]: [STAGE] coarse features end (rows=289421)
[2026-01-22 19:21:00,763] [INFO]: [STAGE] coarse rank start
[2026-01-22 19:21:01,111] [INFO]: [INFO] Coarse rank boundary rows_in=409 score_non_null=409 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 19:21:01,111] [INFO]: [STAGE] coarse rank end (rows=409)
[2026-01-22 19:21:01,132] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=409)
[2026-01-22 19:21:01,163] [INFO]: [STAGE] full features start (shortlist=409)
[2026-01-22 19:25:44,144] [INFO]: [STAGE] full features end (rows=289421)
[2026-01-22 19:25:44,340] [INFO]: [STAGE] finalize candidates pruned rows=289421 -> 257490
[2026-01-22 19:25:44,340] [INFO]: [STAGE] full rank start
[2026-01-22 19:25:44,648] [INFO]: [STAGE] full rank end (rows=409)
[2026-01-22 19:25:44,648] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=409 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 19:25:44,651] [INFO]: [INFO] SENTIMENT_FETCH start target=409 unique=409
[2026-01-22 19:25:44,665] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=CPSH&date=2026-01-22 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x710b11b0a5d0>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))
[2026-01-22 19:25:44,666] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x710b11b0ac10>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))
[2026-01-22 19:25:44,668] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-22 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x710b11b0a990>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))
[2026-01-22 19:25:44,669] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 19:25:50,428] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=409
[2026-01-22 19:25:50,428] [INFO]: [INFO] SENTIMENT_FETCH done target=409 fetched=0 missing=409 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 19:25:50,428] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=409 secs=5.777
[2026-01-22 19:25:50,445] [INFO]: [STAGE] quality filters pruned rows=409 -> 82
[2026-01-22 19:25:50,446] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 19:25:52,843] [INFO]: [INFO] ML_RANK weight=0.30 rows=82 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5735 model=data/models/rank_model.joblib
[2026-01-22 19:25:52,848] [INFO]: [STAGE] gates start
[2026-01-22 19:25:52,863] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-22 19:26:01,415] [INFO]: [SUMMARY] run_ts=2026-01-22T19:15:59Z mode=screener symbols_in=7627 with_bars=409 coarse_rows=409 shortlist_rows=409 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-22 19:26:01,544] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 19:26:01,604] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=82)
[2026-01-22 19:26:01,725] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 19:26:01,729] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 19:26:01,743] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 19:26:01,796] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 19:26:01,797] [INFO]: Screener complete: 7627 symbols examined, 6 candidates.
[2026-01-22T19:26:02.062391+00:00] END screener rc=0 secs=603.5
[2026-01-22T20:26:05.430862+00:00] START screener
[2026-01-22 20:26:06,982] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 20:26:06,988] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 20:26:06,995] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 20:26:07,022] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-21 source=cli
[2026-01-22 20:26:07,022] [INFO]: [STAGE] fetch start
[2026-01-22 20:26:07,570] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 20:26:07,612] [INFO]: Asset metrics: total=13178 tradable_equities=12383 after_filters=12116
[2026-01-22 20:26:07,614] [INFO]: Asset sample: LOTWW:NASDAQ, LOTI:NASDAQ, VHT:ARCA, LOT:NASDAQ, LONZ:ARCA
[2026-01-22 20:26:07,654] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 20:26:07,851] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 20:26:07,863] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 20:26:07,967] [INFO]: Requesting 750 trading days ending 2026-01-21 (2023-01-24T00:00:00Z -> 2026-01-21T23:59:59Z)
[2026-01-22 20:26:08,200] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32069 elapsed=0.2s cache=hit
[2026-01-22 20:26:08,252] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~31537 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,307] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33076 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,364] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32248 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,427] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~36477 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,535] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~31874 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,621] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32718 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,694] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~31448 elapsed=0.1s cache=hit
[2026-01-22 20:26:08,759] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32282 elapsed=0.1s cache=hit
[2026-01-22 20:26:09,447] [INFO]: [BARS_ACCEPT] accepted=418 dropped_missing=32
[2026-01-22 20:26:19,580] [INFO]: [BARS_RETRY] retried=319 recovered=278
[2026-01-22 20:26:20,514] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=1
[2026-01-22 20:26:20,526] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=293395 symbols_with_bars=404
[2026-01-22 20:26:20,526] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-22 20:26:20,526] [INFO]: Bars HTTP empty batches: 2
[2026-01-22 20:26:20,526] [INFO]: Symbols without bars (sample): ['ASIC', 'CBK', 'DMIIR', 'ALH', 'CEPV', 'EGG', 'OYSE', 'YDDL', 'CRAQ', 'MIAX']
[2026-01-22 20:26:20,526] [INFO]: Fallback batches invoked: 1
[2026-01-22 20:26:20,526] [INFO]: Symbols dropped for insufficient history: 31
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-22 20:26:26,300] [INFO]: [STAGE] fetch end (rows=361183, elapsed=19.28s)
[2026-01-22 20:26:26,301] [INFO]: [BARS_DIAG] feed=iex requested=810 with_bars=418 missing=392 examples=[ASIC,CBK,DMIIR,ALH,CEPV,EGG,OYSE,YDDL,CRAQ,MIAX]
[2026-01-22 20:26:26,365] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-22 20:26:31,695] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=361183 symbols=500
[2026-01-22 20:26:31,837] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-22 20:26:32,770] [INFO]: [STAGE] coarse features start
[2026-01-22 20:34:21,494] [INFO]: [STAGE] coarse features end (rows=343989)
[2026-01-22 20:34:21,495] [INFO]: [STAGE] coarse rank start
[2026-01-22 20:34:22,181] [INFO]: [INFO] Coarse rank boundary rows_in=475 score_non_null=475 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-22 20:34:22,181] [INFO]: [STAGE] coarse rank end (rows=475)
[2026-01-22 20:34:22,208] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=475)
[2026-01-22 20:34:22,266] [INFO]: [STAGE] full features start (shortlist=475)
[2026-01-22 20:41:26,036] [INFO]: [STAGE] full features end (rows=343989)
[2026-01-22 20:41:26,264] [INFO]: [STAGE] finalize candidates pruned rows=343989 -> 334005
[2026-01-22 20:41:26,264] [INFO]: [STAGE] full rank start
[2026-01-22 20:41:26,649] [INFO]: [STAGE] full rank end (rows=475)
[2026-01-22 20:41:26,650] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=475 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-22
[2026-01-22 20:41:26,652] [INFO]: [INFO] SENTIMENT_FETCH start target=475 unique=475
[2026-01-22 20:41:26,666] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=PEBO&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x769c397aace0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 20:41:26,668] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=OBK&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x769c397aa740>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 20:41:26,670] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=ALKS&date=2026-01-22 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x769c397a8b50>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-22 20:41:26,672] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-22 20:41:32,550] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=475
[2026-01-22 20:41:32,550] [INFO]: [INFO] SENTIMENT_FETCH done target=475 fetched=0 missing=475 cache_file=data/cache/sentiment/2026-01-22.json
[2026-01-22 20:41:32,550] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=475 secs=5.897
[2026-01-22 20:41:32,569] [INFO]: [STAGE] quality filters pruned rows=475 -> 131
[2026-01-22 20:41:32,571] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-22 20:41:34,508] [INFO]: [INFO] ML_RANK weight=0.30 rows=131 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5635 model=data/models/rank_model.joblib
[2026-01-22 20:41:34,513] [INFO]: [STAGE] gates start
[2026-01-22 20:41:34,527] [INFO]: [STAGE] gates end (candidates=15)
[2026-01-22 20:41:47,143] [INFO]: [SUMMARY] run_ts=2026-01-22T20:26:07Z mode=screener symbols_in=7744 with_bars=475 coarse_rows=475 shortlist_rows=475 final_rows=15 gated_rows=15 fallback_used=false db_ingest_rows=15
[2026-01-22 20:41:47,290] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-22 20:41:47,348] [INFO]: [STAGE] predictions written: data/predictions/2026-01-22.csv (top_n=131)
[2026-01-22 20:41:47,410] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=9 remaining=6
[2026-01-22 20:41:47,443] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-22 20:41:47,446] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-22 20:41:47,457] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-22 20:41:47,504] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-22 20:41:47,504] [INFO]: Screener complete: 7744 symbols examined, 15 candidates.
[2026-01-22T20:41:47.713039+00:00] END screener rc=0 secs=942.3
[2026-01-22T21:00:58.815715+00:00] START screener
[2026-01-22 21:00:59,845] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 21:00:59,853] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 21:00:59,862] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 21:00:59,945] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-22 21:00:59,945] [INFO]: [STAGE] fetch start
[2026-01-22 21:01:00,630] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 21:01:00,668] [INFO]: Asset metrics: total=13179 tradable_equities=12383 after_filters=12116
[2026-01-22 21:01:00,671] [INFO]: Asset sample: GDOT:NYSE, FDX:NYSE, AES:NYSE, GBND:ARCA, FWD:ARCA
[2026-01-22 21:01:00,718] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 21:01:00,937] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 21:01:00,950] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 21:01:01,143] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-22 21:01:02,917] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=1.8s cache=miss
[2026-01-22 21:01:04,427] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=1.5s cache=miss
[2026-01-22 21:01:05,724] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=1.3s cache=miss
[2026-01-22 21:01:07,008] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=1.3s cache=miss
[2026-01-22 21:01:08,369] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=1.4s cache=miss
[2026-01-22 21:01:09,615] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=1.2s cache=miss
[2026-01-22 21:01:10,782] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=1.2s cache=miss
[2026-01-22 21:01:12,113] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=1.3s cache=miss
[2026-01-22 21:01:13,309] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=1.2s cache=miss
[2026-01-22 21:01:14,080] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-22 21:01:15,035] [INFO]: [BARS_RETRY] retried=41 recovered=0
[2026-01-22 21:01:15,766] [ERROR]: [ERROR] ALPACA_UNAUTHORIZED endpoint=/v2/stocks/bars?symbols=ALH&timeframe=1Day&start=2023-01-25T00%3A00%3A00Z&end=2026-01-22T23%3A59%3A59Z&feed=sip&limit=10000 feed=sip hint="check keys/base urls"
[2026-01-22T21:01:15.999789+00:00] END screener rc=2 secs=17.2
[2026-01-22T21:37:21.703306+00:00] START screener
[2026-01-22 21:37:23,243] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 21:37:23,249] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 21:37:23,253] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 21:37:23,283] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-22 21:37:23,283] [INFO]: [STAGE] fetch start
[2026-01-22 21:37:23,882] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 21:37:23,924] [INFO]: Asset metrics: total=13179 tradable_equities=12383 after_filters=12116
[2026-01-22 21:37:23,927] [INFO]: Asset sample: ECO:NYSE, IRET:ARCA, JTEK:NASDAQ, CXW:NYSE, EYEG:NASDAQ
[2026-01-22 21:37:23,992] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 21:37:24,293] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 21:37:24,303] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 21:37:24,397] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-22 21:37:24,491] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-22 21:37:24,546] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.1s cache=hit
[2026-01-22 21:37:24,645] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.1s cache=hit
[2026-01-22 21:37:24,694] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.0s cache=hit
[2026-01-22 21:37:24,742] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-22 21:37:24,828] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-22 21:37:24,879] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.1s cache=hit
[2026-01-22 21:37:24,975] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.1s cache=hit
[2026-01-22 21:37:25,040] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.1s cache=hit
[2026-01-22 21:37:25,917] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-22 21:37:26,741] [INFO]: [BARS_RETRY] retried=41 recovered=0
[2026-01-22 21:37:27,008] [ERROR]: [ERROR] ALPACA_UNAUTHORIZED endpoint=/v2/stocks/bars?symbols=ASIC&timeframe=1Day&start=2023-01-25T00%3A00%3A00Z&end=2026-01-22T23%3A59%3A59Z&feed=sip&limit=10000 feed=sip hint="check keys/base urls"
[2026-01-22T21:37:27.235750+00:00] END screener rc=2 secs=5.5
[2026-01-22T21:43:37.210238+00:00] START screener
[2026-01-22 21:43:38,225] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 21:43:38,230] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 21:43:38,237] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 21:43:38,267] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-22 21:43:38,267] [INFO]: [STAGE] fetch start
[2026-01-22 21:43:38,697] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 21:43:38,735] [INFO]: Asset metrics: total=13179 tradable_equities=12383 after_filters=12116
[2026-01-22 21:43:38,737] [INFO]: Asset sample: BRLN:BATS, QDVO:ARCA, ALOVU:NASDAQ, QEFA:ARCA, QMAG:BATS
[2026-01-22 21:43:38,776] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 21:43:38,958] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 21:43:38,965] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 21:43:39,055] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-22 21:43:39,139] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-22 21:43:39,185] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-22 21:43:39,230] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-22 21:43:39,279] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.0s cache=hit
[2026-01-22 21:43:39,324] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-22 21:43:39,394] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-22 21:43:39,442] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.0s cache=hit
[2026-01-22 21:43:39,490] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.0s cache=hit
[2026-01-22 21:43:39,553] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.1s cache=hit
[2026-01-22 21:43:40,301] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-22 21:43:41,110] [INFO]: [BARS_RETRY] retried=41 recovered=0
[2026-01-22 21:43:41,384] [ERROR]: [ERROR] ALPACA_UNAUTHORIZED endpoint=/v2/stocks/bars?symbols=ASIC&timeframe=1Day&start=2023-01-25T00%3A00%3A00Z&end=2026-01-22T23%3A59%3A59Z&feed=sip&limit=10000 feed=sip hint="check keys/base urls"
[2026-01-22T21:43:41.544246+00:00] END screener rc=2 secs=4.3
[2026-01-22T22:11:58.226224+00:00] START screener
[2026-01-22 22:11:59,316] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 22:11:59,321] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-22 22:11:59,326] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-22 22:11:59,364] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-22 22:11:59,364] [INFO]: [STAGE] fetch start
[2026-01-22 22:11:59,805] [INFO]: Asset meta ready: 12116 symbols (tradable US equities)
[2026-01-22 22:11:59,844] [INFO]: Asset metrics: total=13179 tradable_equities=12383 after_filters=12116
[2026-01-22 22:11:59,847] [INFO]: Asset sample: NXST:NASDAQ, SBIO:ARCA, NXPI:NASDAQ, SBXE.U:NYSE, ECO:NYSE
[2026-01-22 22:11:59,889] [INFO]: Universe sample size: 5881 (of 12116 tradable equities)
[2026-01-22 22:12:00,081] [INFO]: Universe hygiene filtered 5881 -> 4939 symbols
[2026-01-22 22:12:00,089] [INFO]: Universe prefix counts: {'C': 46, 'A': 40, 'B': 28, 'N': 27, 'S': 26, 'G': 26, 'T': 25, 'M': 24, 'F': 23, 'D': 22, 'L': 19, 'I': 17, 'E': 15, 'R': 15, 'P': 15, 'O': 12, 'V': 11, 'W': 11, 'H': 11, 'U': 11, 'K': 9, 'Z': 5, 'J': 4, 'Q': 4, 'X': 3, 'Y': 1}
[2026-01-22 22:12:00,212] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-22 22:12:00,293] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-22 22:12:00,335] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-22 22:12:00,375] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-22 22:12:00,416] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.0s cache=hit
[2026-01-22 22:12:00,456] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-22 22:12:00,527] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-22 22:12:00,579] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.1s cache=hit
[2026-01-22 22:12:00,625] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.0s cache=hit
[2026-01-22 22:12:00,668] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.0s cache=hit
[2026-01-22 22:12:01,511] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-22 22:12:02,574] [INFO]: [BARS_RETRY] retried=41 recovered=0
[2026-01-22 22:12:02,864] [ERROR]: [ERROR] ALPACA_UNAUTHORIZED endpoint=/v2/stocks/bars?symbols=ASIC&timeframe=1Day&start=2023-01-25T00%3A00%3A00Z&end=2026-01-22T23%3A59%3A59Z&feed=sip&limit=10000 feed=sip hint="check keys/base urls"
[2026-01-22T22:12:03.162817+00:00] END screener rc=2 secs=4.9
[2026-01-23T01:37:40.156258+00:00] START screener
[2026-01-23 01:37:41,115] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 01:37:41,120] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 01:37:41,127] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 01:37:41,151] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 01:37:41,151] [INFO]: [STAGE] fetch start
[2026-01-23 01:37:41,605] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 01:37:41,652] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 01:37:41,655] [INFO]: Asset sample: LUCD:NASDAQ, NKTR:NASDAQ, NIO:NYSE, XLB:ARCA, SCIIR:NASDAQ
[2026-01-23 01:37:41,712] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 01:37:41,932] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 01:37:41,953] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 01:37:42,082] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 01:37:42,305] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.2s cache=hit
[2026-01-23 01:37:42,355] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-23 01:37:42,402] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-23 01:37:42,453] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.1s cache=hit
[2026-01-23 01:37:42,499] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-23 01:37:42,577] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-23 01:37:42,625] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.0s cache=hit
[2026-01-23 01:37:42,675] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.0s cache=hit
[2026-01-23 01:37:42,720] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.0s cache=hit
[2026-01-23 01:37:43,381] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 01:37:56,555] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 01:37:59,619] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 01:37:59,627] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 01:37:59,628] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 01:37:59,628] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 01:37:59,628] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 01:37:59,628] [INFO]: Fallback batches invoked: 1
[2026-01-23 01:37:59,628] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 01:38:05,856] [INFO]: [STAGE] fetch end (rows=364450, elapsed=24.70s)
[2026-01-23 01:38:05,856] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 01:38:05,918] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 01:38:10,697] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 01:38:10,832] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 01:38:11,773] [INFO]: [STAGE] coarse features start
[2026-01-23 01:44:40,808] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 01:44:40,809] [INFO]: [STAGE] coarse rank start
[2026-01-23 01:44:41,205] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 01:44:41,205] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 01:44:41,225] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 01:44:41,264] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23 01:51:09,944] [INFO]: [STAGE] full features end (rows=364450)
[2026-01-23 01:51:10,184] [INFO]: [STAGE] finalize candidates pruned rows=364450 -> 357435
[2026-01-23 01:51:10,185] [INFO]: [STAGE] full rank start
[2026-01-23 01:51:10,605] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-23 01:51:10,605] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-23
[2026-01-23 01:51:10,609] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-23 01:51:10,621] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=FFWM&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x78f6ec2ed2a0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 01:51:10,622] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x78f6ec2ed780>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 01:51:10,624] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SSB&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x78f6ec2ee9b0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 01:51:10,626] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-23 01:51:16,630] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-23 01:51:16,630] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-23.json
[2026-01-23 01:51:16,630] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=6.022
[2026-01-23 01:51:16,650] [INFO]: [STAGE] quality filters pruned rows=500 -> 153
[2026-01-23 01:51:16,652] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-23 01:51:18,407] [INFO]: [INFO] ML_RANK weight=0.30 rows=153 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5413 model=data/models/rank_model.joblib
[2026-01-23 01:51:18,412] [INFO]: [STAGE] gates start
[2026-01-23 01:51:18,426] [INFO]: [STAGE] gates end (candidates=12)
[2026-01-23 01:51:35,227] [INFO]: [SUMMARY] run_ts=2026-01-23T01:37:41Z mode=screener symbols_in=7751 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=12 gated_rows=12 fallback_used=false db_ingest_rows=12
[2026-01-23 01:51:35,389] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-23 01:51:35,459] [INFO]: [STAGE] predictions written: data/predictions/2026-01-23.csv (top_n=153)
[2026-01-23 01:51:35,523] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=8
[2026-01-23 01:51:35,559] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=8
[2026-01-23 01:51:35,563] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=8
[2026-01-23 01:51:35,574] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-23 01:51:35,619] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-23 01:51:35,619] [INFO]: Screener complete: 7751 symbols examined, 12 candidates.
[2026-01-23T01:51:35.874937+00:00] END screener rc=0 secs=835.7
[2026-01-23T02:22:10.256831+00:00] START screener
[2026-01-23 02:22:11,308] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 02:22:11,313] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 02:22:11,317] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 02:22:11,340] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 02:22:11,340] [INFO]: [STAGE] fetch start
[2026-01-23 02:22:11,810] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 02:22:11,848] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 02:22:11,850] [INFO]: Asset sample: MOO:ARCA, MOMO:NASDAQ, VTES:ARCA, VTHR:NASDAQ, MOAT:BATS
[2026-01-23 02:22:11,894] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 02:22:12,113] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 02:22:12,125] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 02:22:12,268] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 02:22:12,369] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-23 02:22:12,412] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-23 02:22:12,459] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-23 02:22:12,512] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.1s cache=hit
[2026-01-23 02:22:12,567] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.1s cache=hit
[2026-01-23 02:22:12,664] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-23 02:22:12,707] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.0s cache=hit
[2026-01-23 02:22:12,752] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.0s cache=hit
[2026-01-23 02:22:12,791] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.0s cache=hit
[2026-01-23 02:22:13,494] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 02:22:27,076] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 02:22:29,181] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 02:22:29,190] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 02:22:29,190] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 02:22:29,190] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 02:22:29,190] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 02:22:29,190] [INFO]: Fallback batches invoked: 1
[2026-01-23 02:22:29,190] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 02:22:34,608] [INFO]: [STAGE] fetch end (rows=364450, elapsed=23.27s)
[2026-01-23 02:22:34,609] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 02:22:34,629] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 02:22:40,418] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 02:22:40,531] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 02:22:41,675] [INFO]: [STAGE] coarse features start
[2026-01-23 02:29:24,108] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 02:29:24,108] [INFO]: [STAGE] coarse rank start
[2026-01-23 02:29:24,521] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 02:29:24,521] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 02:29:24,540] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 02:29:24,585] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23 02:36:00,742] [INFO]: [STAGE] full features end (rows=364450)
[2026-01-23 02:36:00,998] [INFO]: [STAGE] finalize candidates pruned rows=364450 -> 357435
[2026-01-23 02:36:00,998] [INFO]: [STAGE] full rank start
[2026-01-23 02:36:01,505] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-23 02:36:01,506] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-23
[2026-01-23 02:36:01,509] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-23 02:36:01,519] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=FFWM&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x711db3598250>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 02:36:01,521] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x711db359b310>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 02:36:01,523] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SSB&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x711db3599480>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 02:36:01,525] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-23 02:36:07,713] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-23 02:36:07,713] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-23.json
[2026-01-23 02:36:07,713] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=6.205
[2026-01-23 02:36:07,734] [INFO]: [STAGE] quality filters pruned rows=500 -> 153
[2026-01-23 02:36:07,736] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-23 02:36:08,415] [INFO]: [INFO] ML_RANK weight=0.30 rows=153 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5413 model=data/models/rank_model.joblib
[2026-01-23 02:36:08,422] [INFO]: [STAGE] gates start
[2026-01-23 02:36:08,436] [INFO]: [STAGE] gates end (candidates=12)
[2026-01-23 02:36:26,224] [INFO]: [SUMMARY] run_ts=2026-01-23T02:22:11Z mode=screener symbols_in=7751 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=12 gated_rows=12 fallback_used=false db_ingest_rows=12
[2026-01-23 02:36:26,394] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-23 02:36:26,467] [INFO]: [STAGE] predictions written: data/predictions/2026-01-23.csv (top_n=153)
[2026-01-23 02:36:26,543] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=8
[2026-01-23 02:36:26,577] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=8
[2026-01-23 02:36:26,580] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=8
[2026-01-23 02:36:26,591] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-23 02:36:26,636] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-23 02:36:26,636] [INFO]: Screener complete: 7751 symbols examined, 12 candidates.
[2026-01-23T02:36:26.874907+00:00] END screener rc=0 secs=856.6
[2026-01-23T02:45:20.526448+00:00] START screener
[2026-01-23 02:45:21,565] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 02:45:21,570] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 02:45:21,574] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 02:45:21,604] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 02:45:21,604] [INFO]: [STAGE] fetch start
[2026-01-23 02:45:22,068] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 02:45:22,109] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 02:45:22,111] [INFO]: Asset sample: TACH:NASDAQ, SCIIR:NASDAQ, NRDS:NASDAQ, NOG:NYSE, VTMX:NYSE
[2026-01-23 02:45:22,154] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 02:45:22,350] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 02:45:22,358] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 02:45:22,447] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 02:45:22,512] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-23 02:45:22,552] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-23 02:45:22,596] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-23 02:45:22,639] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.0s cache=hit
[2026-01-23 02:45:22,679] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-23 02:45:22,747] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-23 02:45:22,790] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.0s cache=hit
[2026-01-23 02:45:22,855] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.1s cache=hit
[2026-01-23 02:45:22,893] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.0s cache=hit
[2026-01-23 02:45:23,570] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 02:45:38,001] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 02:45:39,591] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 02:45:39,599] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 02:45:39,600] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 02:45:39,600] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 02:45:39,600] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 02:45:39,600] [INFO]: Fallback batches invoked: 1
[2026-01-23 02:45:39,600] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 02:45:44,801] [INFO]: [STAGE] fetch end (rows=364450, elapsed=23.20s)
[2026-01-23 02:45:44,801] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 02:45:44,825] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 02:45:49,733] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 02:45:49,845] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 02:45:50,798] [INFO]: [STAGE] coarse features start
[2026-01-23 02:52:29,939] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 02:52:29,940] [INFO]: [STAGE] coarse rank start
[2026-01-23 02:52:30,350] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 02:52:30,350] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 02:52:30,369] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 02:52:30,410] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23 02:59:15,219] [INFO]: [STAGE] full features end (rows=364450)
[2026-01-23 02:59:15,454] [INFO]: [STAGE] finalize candidates pruned rows=364450 -> 357435
[2026-01-23 02:59:15,454] [INFO]: [STAGE] full rank start
[2026-01-23 02:59:15,880] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-23 02:59:15,880] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-23
[2026-01-23 02:59:15,883] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-23 02:59:15,890] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=FFWM&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x752ac1cb90c0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 02:59:15,893] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x752ac1cb8f40>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 02:59:15,895] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SSB&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x752ac1cb9900>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 02:59:15,897] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-23 02:59:22,016] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-23 02:59:22,016] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-23.json
[2026-01-23 02:59:22,016] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=6.132
[2026-01-23 02:59:22,066] [INFO]: [STAGE] quality filters pruned rows=500 -> 153
[2026-01-23 02:59:22,069] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-23 02:59:23,027] [INFO]: [INFO] ML_RANK weight=0.30 rows=153 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5413 model=data/models/rank_model.joblib
[2026-01-23 02:59:23,032] [INFO]: [STAGE] gates start
[2026-01-23 02:59:23,047] [INFO]: [STAGE] gates end (candidates=12)
[2026-01-23 02:59:40,566] [INFO]: [SUMMARY] run_ts=2026-01-23T02:45:21Z mode=screener symbols_in=7751 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=12 gated_rows=12 fallback_used=false db_ingest_rows=12
[2026-01-23 02:59:40,741] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-23 02:59:40,808] [INFO]: [STAGE] predictions written: data/predictions/2026-01-23.csv (top_n=153)
[2026-01-23 02:59:40,875] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=8
[2026-01-23 02:59:40,912] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=8
[2026-01-23 02:59:40,916] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=8
[2026-01-23 02:59:40,927] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-23 02:59:40,970] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-23 02:59:40,970] [INFO]: Screener complete: 7751 symbols examined, 12 candidates.
[2026-01-23T02:59:41.219524+00:00] END screener rc=0 secs=860.7
[2026-01-23T03:25:12.705406+00:00] START screener
[2026-01-23 03:25:13,735] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 03:25:13,739] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 03:25:13,743] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 03:25:13,815] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 03:25:13,815] [INFO]: [STAGE] fetch start
[2026-01-23 03:25:14,237] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 03:25:14,275] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 03:25:14,277] [INFO]: Asset sample: CLX:NYSE, WTI:NYSE, CLWT:NASDAQ, CLW:NYSE, CLVT:NYSE
[2026-01-23 03:25:14,317] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 03:25:14,506] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 03:25:14,514] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 03:25:14,602] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 03:25:14,668] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-23 03:25:14,708] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-23 03:25:14,757] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-23 03:25:14,797] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.0s cache=hit
[2026-01-23 03:25:14,837] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-23 03:25:14,903] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-23 03:25:14,946] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.0s cache=hit
[2026-01-23 03:25:14,987] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.0s cache=hit
[2026-01-23 03:25:15,029] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.0s cache=hit
[2026-01-23 03:25:15,716] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 03:25:25,128] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 03:25:28,733] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 03:25:28,745] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 03:25:28,745] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 03:25:28,745] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 03:25:28,745] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 03:25:28,745] [INFO]: Fallback batches invoked: 1
[2026-01-23 03:25:28,745] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 03:25:34,754] [INFO]: [STAGE] fetch end (rows=364450, elapsed=20.94s)
[2026-01-23 03:25:34,754] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 03:25:34,775] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 03:25:39,954] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 03:25:40,069] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 03:25:40,991] [INFO]: [STAGE] coarse features start
[2026-01-23 03:32:11,829] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 03:32:11,830] [INFO]: [STAGE] coarse rank start
[2026-01-23 03:32:12,312] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 03:32:12,312] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 03:32:12,330] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 03:32:12,372] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23 03:38:47,628] [INFO]: [STAGE] full features end (rows=364450)
[2026-01-23 03:38:47,908] [INFO]: [STAGE] finalize candidates pruned rows=364450 -> 357435
[2026-01-23 03:38:47,908] [INFO]: [STAGE] full rank start
[2026-01-23 03:38:48,320] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-23 03:38:48,320] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-23
[2026-01-23 03:38:48,324] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-23 03:38:48,332] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=FFWM&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x75557b0dc3d0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 03:38:48,334] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x75557b0dc760>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 03:38:48,336] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SSB&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x75557b0dfeb0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 03:38:48,337] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-23 03:38:54,306] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-23 03:38:54,307] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-23.json
[2026-01-23 03:38:54,307] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=5.983
[2026-01-23 03:38:54,345] [INFO]: [STAGE] quality filters pruned rows=500 -> 153
[2026-01-23 03:38:54,348] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-23 03:38:55,114] [INFO]: [INFO] ML_RANK weight=0.30 rows=153 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5413 model=data/models/rank_model.joblib
[2026-01-23 03:38:55,119] [INFO]: [STAGE] gates start
[2026-01-23 03:38:55,137] [INFO]: [STAGE] gates end (candidates=12)
[2026-01-23 03:39:14,760] [INFO]: [SUMMARY] run_ts=2026-01-23T03:25:13Z mode=screener symbols_in=7751 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=12 gated_rows=12 fallback_used=false db_ingest_rows=12
[2026-01-23 03:39:14,924] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-23 03:39:14,995] [INFO]: [STAGE] predictions written: data/predictions/2026-01-23.csv (top_n=153)
[2026-01-23 03:39:15,060] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=8
[2026-01-23 03:39:15,091] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=8
[2026-01-23 03:39:15,094] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=8
[2026-01-23 03:39:15,107] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-23 03:39:15,155] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-23 03:39:15,155] [INFO]: Screener complete: 7751 symbols examined, 12 candidates.
[2026-01-23T03:39:15.398211+00:00] END screener rc=0 secs=842.7
[2026-01-23T03:45:32.619953+00:00] START screener
[2026-01-23 03:45:35,045] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 03:45:35,059] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 03:45:35,079] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 03:45:35,113] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 03:45:35,114] [INFO]: [STAGE] fetch start
[2026-01-23 03:45:36,176] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 03:45:36,253] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 03:45:36,259] [INFO]: Asset sample: CMCM:NYSE, VWAV:NASDAQ, CMCL:AMEX, VWAVW:NASDAQ, CMCI:BATS
[2026-01-23 03:45:36,401] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 03:45:37,049] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 03:45:37,087] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 03:45:37,372] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 03:45:37,822] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.4s cache=hit
[2026-01-23 03:45:37,999] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.2s cache=hit
[2026-01-23 03:45:38,223] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.2s cache=hit
[2026-01-23 03:45:38,356] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.1s cache=hit
[2026-01-23 03:45:38,496] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.1s cache=hit
[2026-01-23 03:45:38,701] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.2s cache=hit
[2026-01-23 03:45:38,827] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.1s cache=hit
[2026-01-23 03:45:38,944] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.1s cache=hit
[2026-01-23 03:45:39,035] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.1s cache=hit
[2026-01-23 03:45:40,898] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 03:45:57,744] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 03:45:59,154] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 03:45:59,171] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 03:45:59,171] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 03:45:59,171] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 03:45:59,171] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 03:45:59,171] [INFO]: Fallback batches invoked: 1
[2026-01-23 03:45:59,172] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 03:46:07,790] [INFO]: [STAGE] fetch end (rows=364450, elapsed=32.68s)
[2026-01-23 03:46:07,790] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 03:46:07,833] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 03:46:18,293] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 03:46:18,447] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 03:46:19,977] [INFO]: [STAGE] coarse features start
[2026-01-23 03:54:00,548] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 03:54:00,549] [INFO]: [STAGE] coarse rank start
[2026-01-23 03:54:00,962] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 03:54:00,962] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 03:54:00,982] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 03:54:01,022] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23T03:55:20.701963+00:00] START screener
[2026-01-23 03:55:21,783] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 03:55:21,788] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 03:55:21,792] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 03:55:21,818] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 03:55:21,818] [INFO]: [STAGE] fetch start
[2026-01-23 03:55:22,258] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 03:55:22,296] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 03:55:22,298] [INFO]: Asset sample: WBIG:ARCA, WBIL:ARCA, CMCSA:NASDAQ, WBIY:NYSE, CMCO:NASDAQ
[2026-01-23 03:55:22,340] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 03:55:22,560] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 03:55:22,569] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 03:55:22,655] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 03:55:22,754] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.1s cache=hit
[2026-01-23 03:55:22,801] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-23 03:55:22,841] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.0s cache=hit
[2026-01-23 03:55:22,882] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.0s cache=hit
[2026-01-23 03:55:22,921] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-23 03:55:22,984] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-23 03:55:23,026] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.0s cache=hit
[2026-01-23 03:55:23,068] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.0s cache=hit
[2026-01-23 03:55:23,110] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.0s cache=hit
[2026-01-23 03:55:23,791] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 03:55:33,888] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 03:55:37,991] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 03:55:37,999] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 03:55:37,999] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 03:55:37,999] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 03:55:38,000] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 03:55:38,000] [INFO]: Fallback batches invoked: 1
[2026-01-23 03:55:38,000] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 03:55:43,407] [INFO]: [STAGE] fetch end (rows=364450, elapsed=21.59s)
[2026-01-23 03:55:43,407] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 03:55:43,429] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 03:55:48,296] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 03:55:48,407] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 03:55:49,363] [INFO]: [STAGE] coarse features start
[2026-01-23 04:02:44,378] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 04:02:44,379] [INFO]: [STAGE] coarse rank start
[2026-01-23 04:02:44,792] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 04:02:44,792] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 04:02:44,812] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 04:02:44,850] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23 04:04:06,813] [INFO]: [STAGE] full features end (rows=364450)
[2026-01-23 04:04:07,801] [INFO]: [STAGE] finalize candidates pruned rows=364450 -> 357435
[2026-01-23 04:04:07,801] [INFO]: [STAGE] full rank start
[2026-01-23 04:04:09,025] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-23 04:04:09,025] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-23
[2026-01-23 04:04:09,031] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-23 04:04:09,048] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=FFWM&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7ee9c03e8e20>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 04:04:09,055] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7ee9c03e8880>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 04:04:09,061] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SSB&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7ee9c03ebe80>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 04:04:09,065] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-23 04:04:11,461] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-23 04:04:11,461] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-23.json
[2026-01-23 04:04:11,461] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=2.430
[2026-01-23 04:04:11,519] [INFO]: [STAGE] quality filters pruned rows=500 -> 153
[2026-01-23 04:04:11,522] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-23 04:04:15,197] [INFO]: [INFO] ML_RANK weight=0.30 rows=153 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5413 model=data/models/rank_model.joblib
[2026-01-23 04:04:15,216] [INFO]: [STAGE] gates start
[2026-01-23 04:04:15,246] [INFO]: [STAGE] gates end (candidates=12)
[2026-01-23 04:04:38,637] [INFO]: [SUMMARY] run_ts=2026-01-23T03:45:35Z mode=screener symbols_in=7751 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=12 gated_rows=12 fallback_used=false db_ingest_rows=12
[2026-01-23 04:04:38,834] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-23 04:04:38,912] [INFO]: [STAGE] predictions written: data/predictions/2026-01-23.csv (top_n=153)
[2026-01-23 04:04:38,982] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=8
[2026-01-23 04:04:39,023] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=8
[2026-01-23 04:04:39,027] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=8
[2026-01-23 04:04:39,043] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-23 04:04:39,093] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-23 04:04:39,094] [INFO]: Screener complete: 7751 symbols examined, 12 candidates.
[2026-01-23T04:04:39.442675+00:00] END screener rc=0 secs=1146.8
[2026-01-23 04:09:35,096] [INFO]: [STAGE] full features end (rows=364450)
[2026-01-23 04:09:35,342] [INFO]: [STAGE] finalize candidates pruned rows=364450 -> 357435
[2026-01-23 04:09:35,342] [INFO]: [STAGE] full rank start
[2026-01-23 04:09:35,767] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-23 04:09:35,767] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-23
[2026-01-23 04:09:35,770] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-23 04:09:35,780] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=FFWM&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x703311e508e0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 04:09:35,782] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=WBS&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x703311e52740>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 04:09:35,783] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SSB&date=2026-01-23 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x703311e53190>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-23 04:09:35,786] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-23 04:09:46,651] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-23 04:09:46,651] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-23.json
[2026-01-23 04:09:46,651] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=10.881
[2026-01-23 04:09:46,672] [INFO]: [STAGE] quality filters pruned rows=500 -> 153
[2026-01-23 04:09:46,673] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-23 04:09:47,401] [INFO]: [INFO] ML_RANK weight=0.30 rows=153 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5413 model=data/models/rank_model.joblib
[2026-01-23 04:09:47,407] [INFO]: [STAGE] gates start
[2026-01-23 04:09:47,422] [INFO]: [STAGE] gates end (candidates=12)
[2026-01-23 04:10:05,798] [INFO]: [SUMMARY] run_ts=2026-01-23T03:55:21Z mode=screener symbols_in=7751 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=12 gated_rows=12 fallback_used=false db_ingest_rows=12
[2026-01-23 04:10:06,006] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-23 04:10:06,068] [INFO]: [STAGE] predictions written: data/predictions/2026-01-23.csv (top_n=153)
[2026-01-23 04:10:06,129] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=8
[2026-01-23 04:10:06,160] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=8
[2026-01-23 04:10:06,163] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=8
[2026-01-23 04:10:06,175] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-23 04:10:06,222] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-23 04:10:06,222] [INFO]: Screener complete: 7751 symbols examined, 12 candidates.
[2026-01-23T04:10:06.469902+00:00] END screener rc=0 secs=885.8
[2026-01-23T04:26:14.427705+00:00] START screener
[2026-01-23 04:26:15,426] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 04:26:15,434] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-23 04:26:15,441] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-23 04:26:15,466] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-22 source=cli
[2026-01-23 04:26:15,466] [INFO]: [STAGE] fetch start
[2026-01-23 04:26:15,949] [INFO]: Asset meta ready: 12112 symbols (tradable US equities)
[2026-01-23 04:26:15,993] [INFO]: Asset metrics: total=13179 tradable_equities=12379 after_filters=12112
[2026-01-23 04:26:15,995] [INFO]: Asset sample: CMCT:NASDAQ, CMCSA:NASDAQ, CMCO:NASDAQ, WCEO:ARCA, CMCM:NYSE
[2026-01-23 04:26:16,036] [INFO]: Universe sample size: 5877 (of 12112 tradable equities)
[2026-01-23 04:26:16,227] [INFO]: Universe hygiene filtered 5877 -> 4935 symbols
[2026-01-23 04:26:16,238] [INFO]: Universe prefix counts: {'A': 52, 'S': 41, 'C': 36, 'M': 32, 'B': 29, 'T': 24, 'P': 20, 'N': 20, 'D': 19, 'R': 19, 'G': 18, 'H': 17, 'V': 17, 'F': 16, 'L': 15, 'E': 12, 'I': 11, 'K': 10, 'O': 9, 'X': 6, 'U': 6, 'W': 6, 'Z': 5, 'Q': 4, 'J': 4, 'Y': 2}
[2026-01-23 04:26:16,327] [INFO]: Requesting 750 trading days ending 2026-01-22 (2023-01-25T00:00:00Z -> 2026-01-22T23:59:59Z)
[2026-01-23 04:26:16,536] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~32048 elapsed=0.2s cache=hit
[2026-01-23 04:26:16,585] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32756 elapsed=0.0s cache=hit
[2026-01-23 04:26:16,656] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~33467 elapsed=0.1s cache=hit
[2026-01-23 04:26:16,709] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~34194 elapsed=0.1s cache=hit
[2026-01-23 04:26:16,756] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~31742 elapsed=0.0s cache=hit
[2026-01-23 04:26:16,835] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~29374 elapsed=0.1s cache=hit
[2026-01-23 04:26:16,918] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~32333 elapsed=0.1s cache=hit
[2026-01-23 04:26:16,981] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~33240 elapsed=0.1s cache=hit
[2026-01-23 04:26:17,041] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~30634 elapsed=0.1s cache=hit
[2026-01-23 04:26:17,905] [INFO]: [BARS_ACCEPT] accepted=409 dropped_missing=41
[2026-01-23 04:26:31,510] [INFO]: [BARS_RETRY] retried=408 recovered=374
[2026-01-23 04:26:37,125] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=2
[2026-01-23 04:26:37,133] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=289457 symbols_with_bars=396
[2026-01-23 04:26:37,134] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-23 04:26:37,134] [INFO]: Bars HTTP empty batches: 1
[2026-01-23 04:26:37,134] [INFO]: Symbols without bars (sample): ['DEFT', 'Q', 'SVAC', 'VBIX', 'STUB', 'GURE', 'KWM', 'SCZM', 'REED', 'MCGA']
[2026-01-23 04:26:37,134] [INFO]: Fallback batches invoked: 1
[2026-01-23 04:26:37,134] [INFO]: Symbols dropped for insufficient history: 40
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-23 04:26:42,725] [INFO]: [STAGE] fetch end (rows=364450, elapsed=27.26s)
[2026-01-23 04:26:42,725] [INFO]: [BARS_DIAG] feed=iex requested=892 with_bars=409 missing=483 examples=[DEFT,Q,SVAC,VBIX,STUB,GURE,KWM,SCZM,REED,MCGA]
[2026-01-23 04:26:42,747] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-23 04:26:48,099] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=364450 symbols=500
[2026-01-23 04:26:48,231] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-23 04:26:49,298] [INFO]: [STAGE] coarse features start
[2026-01-23 04:34:35,617] [INFO]: [STAGE] coarse features end (rows=364450)
[2026-01-23 04:34:35,617] [INFO]: [STAGE] coarse rank start
[2026-01-23 04:34:36,070] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-23 04:34:36,070] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-23 04:34:36,089] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-23 04:34:36,130] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-23T04:46:15.851002+00:00] END screener rc=-9 secs=1201.4
[2026-01-24T03:45:28.325532+00:00] START screener
[2026-01-24 03:45:29,516] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-24 03:45:29,522] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-24 03:45:29,529] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-24 03:45:29,559] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-23 source=cli
[2026-01-24 03:45:29,559] [INFO]: [STAGE] fetch start
[2026-01-24 03:45:30,043] [INFO]: Asset meta ready: 12124 symbols (tradable US equities)
[2026-01-24 03:45:30,086] [INFO]: Asset metrics: total=13187 tradable_equities=12390 after_filters=12124
[2026-01-24 03:45:30,089] [INFO]: Asset sample: CAG:NYSE, SUUN:NASDAQ, ALOVU:NASDAQ, MOVE:NASDAQ, ALOT:NASDAQ
[2026-01-24 03:45:30,131] [INFO]: Universe sample size: 5884 (of 12124 tradable equities)
[2026-01-24 03:45:30,346] [INFO]: Universe hygiene filtered 5884 -> 4942 symbols
[2026-01-24 03:45:30,358] [INFO]: Universe prefix counts: {'A': 58, 'C': 47, 'S': 35, 'B': 26, 'T': 24, 'M': 24, 'G': 23, 'I': 23, 'N': 22, 'E': 22, 'L': 17, 'U': 16, 'P': 15, 'H': 15, 'D': 14, 'K': 11, 'F': 10, 'W': 10, 'O': 9, 'R': 9, 'V': 7, 'J': 4, 'X': 3, 'Q': 3, 'Y': 2, 'Z': 1}
[2026-01-24 03:45:30,462] [INFO]: Requesting 750 trading days ending 2026-01-23 (2023-01-26T00:00:00Z -> 2026-01-23T23:59:59Z)
[2026-01-24 03:45:31,703] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~29186 elapsed=1.2s cache=miss
[2026-01-24 03:45:32,906] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32962 elapsed=1.2s cache=miss
[2026-01-24 03:45:34,321] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~34388 elapsed=1.4s cache=miss
[2026-01-24 03:45:35,581] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32708 elapsed=1.3s cache=miss
[2026-01-24 03:45:36,765] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32426 elapsed=1.2s cache=miss
[2026-01-24 03:45:37,930] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~33533 elapsed=1.2s cache=miss
[2026-01-24 03:45:39,102] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34732 elapsed=1.2s cache=miss
[2026-01-24 03:45:40,297] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35116 elapsed=1.2s cache=miss
[2026-01-24 03:45:41,456] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32311 elapsed=1.2s cache=miss
[2026-01-24 03:45:42,362] [INFO]: [BARS_ACCEPT] accepted=414 dropped_missing=36
[2026-01-24 03:45:43,131] [INFO]: [BARS_RETRY] retried=36 recovered=0
[2026-01-24 03:45:43,847] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-24 03:45:43,865] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=297027 symbols_with_bars=406
[2026-01-24 03:45:43,865] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-24 03:45:43,865] [INFO]: Symbols without bars (sample): ['FIEE', 'HNGE', 'MAMK', 'UYSCR', 'SOMN', 'NOMA', 'LCCC', 'PMTR', 'DLXY', 'AEBI']
[2026-01-24 03:45:43,865] [INFO]: Fallback batches invoked: 1
[2026-01-24 03:45:43,865] [INFO]: Symbols dropped for insufficient history: 36
[2026-01-24 03:45:48,938] [INFO]: [STAGE] fetch end (rows=297027, elapsed=19.38s)
[2026-01-24 03:45:48,938] [INFO]: [BARS_DIAG] feed=iex requested=522 with_bars=414 missing=108 examples=[FIEE,HNGE,MAMK,UYSCR,SOMN,NOMA,LCCC,PMTR,DLXY,AEBI]
[2026-01-24 03:45:48,962] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-24 03:45:53,349] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=297027 symbols=414
[2026-01-24 03:45:53,534] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-24 03:45:54,391] [INFO]: [STAGE] coarse features start
[2026-01-24 03:51:46,121] [INFO]: [STAGE] coarse features end (rows=297027)
[2026-01-24 03:51:46,122] [INFO]: [STAGE] coarse rank start
[2026-01-24 03:51:46,478] [INFO]: [INFO] Coarse rank boundary rows_in=414 score_non_null=414 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-24 03:51:46,478] [INFO]: [STAGE] coarse rank end (rows=414)
[2026-01-24 03:51:46,504] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=414)
[2026-01-24 03:51:46,540] [INFO]: [STAGE] full features start (shortlist=414)
[2026-01-24 03:57:31,377] [INFO]: [STAGE] full features end (rows=297027)
[2026-01-24 03:57:31,631] [INFO]: [STAGE] finalize candidates pruned rows=297027 -> 258654
[2026-01-24 03:57:31,631] [INFO]: [STAGE] full rank start
[2026-01-24 03:57:31,972] [INFO]: [STAGE] full rank end (rows=414)
[2026-01-24 03:57:31,972] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=414 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-24
[2026-01-24 03:57:31,975] [INFO]: [INFO] SENTIMENT_FETCH start target=414 unique=414
[2026-01-24 03:57:31,988] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SOHO&date=2026-01-24 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7cc5807fa890>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-24 03:57:31,990] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=GTN.A&date=2026-01-24 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7cc5807f8580>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-24 03:57:31,992] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=REI&date=2026-01-24 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7cc5807f8dc0>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-24 03:57:31,994] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-24 03:57:32,649] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=414
[2026-01-24 03:57:32,649] [INFO]: [INFO] SENTIMENT_FETCH done target=414 fetched=0 missing=414 cache_file=data/cache/sentiment/2026-01-24.json
[2026-01-24 03:57:32,649] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=414 secs=0.673
[2026-01-24 03:57:32,669] [INFO]: [STAGE] quality filters pruned rows=414 -> 83
[2026-01-24 03:57:32,671] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-24 03:57:34,642] [INFO]: [INFO] ML_RANK weight=0.30 rows=83 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5255 model=data/models/rank_model.joblib
[2026-01-24 03:57:34,648] [INFO]: [STAGE] gates start
[2026-01-24 03:57:34,663] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-24 03:57:48,043] [INFO]: [SUMMARY] run_ts=2026-01-24T03:45:29Z mode=screener symbols_in=7632 with_bars=414 coarse_rows=414 shortlist_rows=414 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-24 03:57:48,184] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-24 03:57:48,236] [INFO]: [STAGE] predictions written: data/predictions/2026-01-24.csv (top_n=83)
[2026-01-24 03:57:48,334] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=6
[2026-01-24 03:57:48,337] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=6
[2026-01-24 03:57:48,350] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-24 03:57:48,402] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-24 03:57:48,403] [INFO]: Screener complete: 7632 symbols examined, 6 candidates.
[2026-01-24T03:57:48.679043+00:00] END screener rc=0 secs=740.4
[2026-01-25T03:45:28.910845+00:00] START screener
[2026-01-25 03:45:30,282] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-25 03:45:30,287] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-25 03:45:30,296] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-25 03:45:30,325] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-23 source=cli
[2026-01-25 03:45:30,325] [INFO]: [STAGE] fetch start
[2026-01-25 03:45:30,867] [INFO]: Asset meta ready: 12124 symbols (tradable US equities)
[2026-01-25 03:45:30,910] [INFO]: Asset metrics: total=13187 tradable_equities=12390 after_filters=12124
[2026-01-25 03:45:30,913] [INFO]: Asset sample: CMRE:NYSE, KSLV:BATS, KSEP:BATS, KSCP:NASDAQ, CMRC:NASDAQ
[2026-01-25 03:45:30,961] [INFO]: Universe sample size: 5884 (of 12124 tradable equities)
[2026-01-25 03:45:31,168] [INFO]: Universe hygiene filtered 5884 -> 4942 symbols
[2026-01-25 03:45:31,183] [INFO]: Universe prefix counts: {'A': 49, 'S': 46, 'T': 35, 'C': 35, 'B': 29, 'P': 24, 'R': 22, 'M': 20, 'D': 19, 'H': 18, 'N': 16, 'L': 16, 'E': 16, 'I': 14, 'V': 13, 'W': 13, 'F': 12, 'G': 10, 'O': 8, 'K': 7, 'U': 6, 'X': 6, 'Z': 5, 'Q': 5, 'J': 4, 'Y': 2}
[2026-01-25 03:45:31,272] [INFO]: Requesting 750 trading days ending 2026-01-23 (2023-01-26T00:00:00Z -> 2026-01-23T23:59:59Z)
[2026-01-25 03:45:31,591] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~29186 elapsed=0.3s cache=hit
[2026-01-25 03:45:31,659] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32962 elapsed=0.1s cache=hit
[2026-01-25 03:45:31,738] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~34388 elapsed=0.1s cache=hit
[2026-01-25 03:45:31,796] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32708 elapsed=0.1s cache=hit
[2026-01-25 03:45:31,853] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32426 elapsed=0.1s cache=hit
[2026-01-25 03:45:31,953] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~33533 elapsed=0.1s cache=hit
[2026-01-25 03:45:32,012] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34732 elapsed=0.1s cache=hit
[2026-01-25 03:45:32,069] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35116 elapsed=0.1s cache=hit
[2026-01-25 03:45:32,123] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32311 elapsed=0.1s cache=hit
[2026-01-25 03:45:32,894] [INFO]: [BARS_ACCEPT] accepted=414 dropped_missing=36
[2026-01-25 03:45:51,316] [INFO]: [BARS_RETRY] retried=408 recovered=388
[2026-01-25 03:45:51,687] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-25 03:45:51,697] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=297027 symbols_with_bars=406
[2026-01-25 03:45:51,697] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-25 03:45:51,697] [INFO]: Bars HTTP empty batches: 1
[2026-01-25 03:45:51,698] [INFO]: Symbols without bars (sample): ['APACR', 'MCGA', 'DAAQ', 'FIEE', 'SBXE', 'BPAC', 'IPCX', 'ACFN', 'BTQ', 'RNGT']
[2026-01-25 03:45:51,698] [INFO]: Fallback batches invoked: 1
[2026-01-25 03:45:51,698] [INFO]: Symbols dropped for insufficient history: 36
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-25 03:45:57,957] [INFO]: [STAGE] fetch end (rows=367101, elapsed=27.63s)
[2026-01-25 03:45:57,957] [INFO]: [BARS_DIAG] feed=iex requested=878 with_bars=414 missing=464 examples=[APACR,MCGA,DAAQ,FIEE,SBXE,BPAC,IPCX,ACFN,BTQ,RNGT]
[2026-01-25 03:45:57,978] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-25 03:46:03,544] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=367101 symbols=500
[2026-01-25 03:46:03,774] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-25 03:46:05,619] [INFO]: [STAGE] coarse features start
[2026-01-25 03:53:05,228] [INFO]: [STAGE] coarse features end (rows=367101)
[2026-01-25 03:53:05,232] [INFO]: [STAGE] coarse rank start
[2026-01-25 03:53:06,316] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-25 03:53:06,316] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-25 03:53:06,342] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-25 03:53:06,405] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-25 03:59:50,630] [INFO]: [STAGE] full features end (rows=367101)
[2026-01-25 03:59:51,043] [INFO]: [STAGE] finalize candidates pruned rows=367101 -> 356301
[2026-01-25 03:59:51,043] [INFO]: [STAGE] full rank start
[2026-01-25 03:59:51,466] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-25 03:59:51,466] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-25
[2026-01-25 03:59:51,469] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-25 03:59:51,483] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=BKD&date=2026-01-25 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f0a2c48dc60>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-25 03:59:51,485] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SKE&date=2026-01-25 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f0a2c48ee00>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-25 03:59:51,486] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=REI&date=2026-01-25 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7f0a2c48fd90>: Failed to resolve 'sentiment.example.com' ([Errno -5] No address associated with hostname)"))
[2026-01-25 03:59:51,488] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-25 03:59:57,275] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-25 03:59:57,275] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-25.json
[2026-01-25 03:59:57,275] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=5.806
[2026-01-25 03:59:57,296] [INFO]: [STAGE] quality filters pruned rows=500 -> 150
[2026-01-25 03:59:57,298] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-25 03:59:59,269] [INFO]: [INFO] ML_RANK weight=0.30 rows=150 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.5308 model=data/models/rank_model.joblib
[2026-01-25 03:59:59,275] [INFO]: [STAGE] gates start
[2026-01-25 03:59:59,290] [INFO]: [STAGE] gates end (candidates=6)
[2026-01-25 04:01:36,722] [INFO]: [SUMMARY] run_ts=2026-01-25T03:45:30Z mode=screener symbols_in=7736 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=6 gated_rows=6 fallback_used=false db_ingest_rows=6
[2026-01-25 04:01:38,346] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-25 04:01:38,879] [INFO]: [STAGE] predictions written: data/predictions/2026-01-25.csv (top_n=150)
[2026-01-25 04:01:39,294] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=3 remaining=3
[2026-01-25 04:01:39,380] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-25 04:01:39,396] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-25 04:01:39,433] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-25 04:01:39,569] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-25 04:01:39,569] [INFO]: Screener complete: 7736 symbols examined, 6 candidates.
[2026-01-25T04:01:42.317115+00:00] END screener rc=0 secs=973.4
[2026-01-26T03:45:34.403104+00:00] START screener
[2026-01-26 03:45:36,565] [INFO]: Script started
[INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-26 03:45:36,575] [INFO]: [INFO] ENV_LOADED files=["/home/RasPatrick/.config/jbravo/.env"]
[2026-01-26 03:45:36,583] [INFO]: [INFO] ALPACA_CREDENTIALS_OK sanitized={"base_urls": {"data": "https://data.alpaca.markets", "trading": "https://paper-api.alpaca.markets"}, "key_prefix": "PK7I\u2026", "secret_len": 40}
[2026-01-26 03:45:36,615] [INFO]: [INFO] STEP_RUN_DATE step=screener run_date=2026-01-23 source=cli
[2026-01-26 03:45:36,615] [INFO]: [STAGE] fetch start
[2026-01-26 03:45:37,389] [INFO]: Asset meta ready: 12124 symbols (tradable US equities)
[2026-01-26 03:45:37,451] [INFO]: Asset metrics: total=13187 tradable_equities=12390 after_filters=12124
[2026-01-26 03:45:37,455] [INFO]: Asset sample: QLVD:ARCA, QLYS:NASDAQ, BJK:NASDAQ, FTAI:NASDAQ, FTAG:NASDAQ
[2026-01-26 03:45:37,572] [INFO]: Universe sample size: 5884 (of 12124 tradable equities)
[2026-01-26 03:45:37,942] [INFO]: Universe hygiene filtered 5884 -> 4942 symbols
[2026-01-26 03:45:37,963] [INFO]: Universe prefix counts: {'A': 38, 'C': 37, 'S': 31, 'B': 31, 'M': 28, 'P': 26, 'F': 22, 'E': 20, 'H': 18, 'G': 17, 'L': 17, 'T': 17, 'N': 17, 'I': 16, 'V': 16, 'K': 15, 'R': 15, 'O': 14, 'D': 14, 'J': 11, 'W': 10, 'U': 8, 'X': 5, 'Z': 4, 'Q': 2, 'Y': 1}
[2026-01-26 03:45:38,154] [INFO]: Requesting 750 trading days ending 2026-01-23 (2023-01-26T00:00:00Z -> 2026-01-23T23:59:59Z)
[2026-01-26 03:45:38,467] [INFO]: [INFO] bars: batch 01/09 syms=50 pages=4 rows=~29186 elapsed=0.3s cache=hit
[2026-01-26 03:45:38,536] [INFO]: [INFO] bars: batch 02/09 syms=50 pages=4 rows=~32962 elapsed=0.1s cache=hit
[2026-01-26 03:45:38,603] [INFO]: [INFO] bars: batch 03/09 syms=50 pages=4 rows=~34388 elapsed=0.1s cache=hit
[2026-01-26 03:45:38,672] [INFO]: [INFO] bars: batch 04/09 syms=50 pages=4 rows=~32708 elapsed=0.1s cache=hit
[2026-01-26 03:45:38,760] [INFO]: [INFO] bars: batch 05/09 syms=50 pages=4 rows=~32426 elapsed=0.1s cache=hit
[2026-01-26 03:45:38,863] [INFO]: [INFO] bars: batch 06/09 syms=50 pages=4 rows=~33533 elapsed=0.1s cache=hit
[2026-01-26 03:45:38,937] [INFO]: [INFO] bars: batch 07/09 syms=50 pages=4 rows=~34732 elapsed=0.1s cache=hit
[2026-01-26 03:45:39,006] [INFO]: [INFO] bars: batch 08/09 syms=50 pages=4 rows=~35116 elapsed=0.1s cache=hit
[2026-01-26 03:45:39,116] [INFO]: [INFO] bars: batch 09/09 syms=50 pages=4 rows=~32311 elapsed=0.1s cache=hit
[2026-01-26 03:45:40,227] [INFO]: [BARS_ACCEPT] accepted=414 dropped_missing=36
[2026-01-26 03:45:56,392] [INFO]: [BARS_RETRY] retried=415 recovered=374
[2026-01-26 03:45:59,865] [INFO]: [BARS_FEED_FALLBACK] from=iex to=sip recovered=0
[2026-01-26 03:45:59,901] [INFO]: Bars fetch metrics: batches=9 paged=9 pages=36 rows=297027 symbols_with_bars=406
[2026-01-26 03:45:59,902] [INFO]: Bars window attempts: [750] -> used=750
[2026-01-26 03:45:59,902] [INFO]: Symbols without bars (sample): ['IPCXR', 'GEMI', 'ANPA', 'CRAC', 'WSTN', 'WBUY', 'QUMS', 'MMTX', 'KCHV', 'ALPS']
[2026-01-26 03:45:59,902] [INFO]: Fallback batches invoked: 1
[2026-01-26 03:45:59,905] [INFO]: Symbols dropped for insufficient history: 36
/home/RasPatrick/jbravo_screener/scripts/screener.py:2051: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  result["tradable"] = result["tradable"].fillna(True).astype(bool)
[2026-01-26 03:46:10,856] [INFO]: [STAGE] fetch end (rows=366268, elapsed=34.24s)
[2026-01-26 03:46:10,857] [INFO]: [BARS_DIAG] feed=iex requested=906 with_bars=414 missing=492 examples=[IPCXR,GEMI,ANPA,CRAC,WSTN,WBUY,QUMS,MMTX,KCHV,ALPS]
[2026-01-26 03:46:10,920] [INFO]: [INFO] DB_WRITE_OK table=bar_coverage_app rows=1
[2026-01-26 03:46:18,461] [INFO]: [INFO] DAILY_BARS_EXPORTED path=/home/RasPatrick/jbravo_screener/data/daily_bars.csv rows=366268 symbols=500
[2026-01-26 03:46:18,626] [INFO]: [INFO] SENTIMENT enabled=True url_set=True weight=0.250 min=-0.200
[2026-01-26 03:46:19,899] [INFO]: [STAGE] coarse features start
[2026-01-26 03:53:11,695] [INFO]: [STAGE] coarse features end (rows=366268)
[2026-01-26 03:53:11,696] [INFO]: [STAGE] coarse rank start
[2026-01-26 03:53:12,355] [INFO]: [INFO] Coarse rank boundary rows_in=500 score_non_null=500 cols=symbol,timestamp,TS,PT,RSI,MACD_HIST,ADX,AROON,VCP,VOLexp,REL_VOLUME_x,OBV_DELTA_x,BB_BANDWIDTH_x,ATR_pct,GAPpen,LIQpen,close,volume,exchange,history,REL_VOLUME_y,OBV,OBV_DELTA_y,BB_UPPER,BB_LOWER,BB_BANDWIDTH_y,SQUEEZE_ON,SMA9,EMA20,SMA180,WK52_PROX,RS20_SLOPE,RSI14,MACD,AROON_UP,AROON_DN,REL_VOLUME,OBV_DELTA,BB_BANDWIDTH,prev_MACD_HIST,prev_AROON_UP,prev_AROON_DN,Score,trend_score,momentum_score,volume_score,volatility_score,risk_score,trend_contribution,momentum_contribution,volume_contribution,volatility_contribution,risk_contribution,wk52_bonus_contribution,wk52_bonus,rs_bonus_contribution,rs_bonus,score_breakdown,component_breakdown,coarse_score
[2026-01-26 03:53:12,355] [INFO]: [STAGE] coarse rank end (rows=500)
[2026-01-26 03:53:12,384] [INFO]: [STAGE] shortlist written: data/tmp/shortlist.csv (rows=500)
[2026-01-26 03:53:12,441] [INFO]: [STAGE] full features start (shortlist=500)
[2026-01-26 03:59:55,886] [INFO]: [STAGE] full features end (rows=366268)
[2026-01-26 03:59:56,476] [INFO]: [STAGE] finalize candidates pruned rows=366268 -> 354072
[2026-01-26 03:59:56,476] [INFO]: [STAGE] full rank start
[2026-01-26 03:59:57,084] [INFO]: [STAGE] full rank end (rows=500)
[2026-01-26 03:59:57,084] [INFO]: [INFO] SENTIMENT_STAGE enter df_rows=500 cols_has_symbol=True cache_dir=data/cache/sentiment run_date=2026-01-26
[2026-01-26 03:59:57,087] [INFO]: [INFO] SENTIMENT_FETCH start target=500 unique=500
[2026-01-26 03:59:57,099] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SEE&date=2026-01-26 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x787604508df0>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))
[2026-01-26 03:59:57,101] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=DSX&date=2026-01-26 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7876045080a0>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))
[2026-01-26 03:59:57,103] [WARNING]: Sentiment fetch failed: HTTPSConnectionPool(host='sentiment.example.com', port=443): Max retries exceeded with url: /?symbol=SKE&date=2026-01-26 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x78760450b040>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))
[2026-01-26 03:59:57,104] [WARNING]: Further sentiment fetch errors suppressed
[2026-01-26 04:00:03,030] [INFO]: [INFO] SENTIMENT_FETCH skip cache persist reason=empty_payload target=500
[2026-01-26 04:00:03,030] [INFO]: [INFO] SENTIMENT_FETCH done target=500 fetched=0 missing=500 cache_file=data/cache/sentiment/2026-01-26.json
[2026-01-26 04:00:03,030] [INFO]: [INFO] SENTIMENT_FETCH stats cache_hit=0 errors=500 secs=5.943
[2026-01-26 04:00:03,071] [INFO]: [STAGE] quality filters pruned rows=500 -> 151
[2026-01-26 04:00:03,074] [INFO]: Rank model not found at data/models/rank_model.joblib; skipping ML ranking
[2026-01-26 04:00:05,342] [INFO]: [INFO] ML_RANK weight=0.30 rows=151 prob_up_non_null=0 prob_up_mean=0.0000 rank_corr=1.0000 final_score_mean=0.4964 model=data/models/rank_model.joblib
[2026-01-26 04:00:05,347] [INFO]: [STAGE] gates start
[2026-01-26 04:00:05,362] [INFO]: [STAGE] gates end (candidates=7)
[2026-01-26 04:01:58,206] [INFO]: [SUMMARY] run_ts=2026-01-26T03:45:36Z mode=screener symbols_in=7756 with_bars=500 coarse_rows=500 shortlist_rows=500 final_rows=7 gated_rows=7 fallback_used=false db_ingest_rows=7
[2026-01-26 04:01:58,582] [INFO]: [INFO] CANDIDATE_CSV_SKIPPED reason=db_enabled
[2026-01-26 04:01:58,687] [INFO]: [STAGE] predictions written: data/predictions/2026-01-26.csv (top_n=151)
[2026-01-26 04:01:58,795] [WARNING]: [WARN] SCREENER_CANDIDATES_INCOMPLETE dropped=4 remaining=3
[2026-01-26 04:01:58,850] [INFO]: [INFO] DB_INGEST_OK table=screener_candidates rows=3
[2026-01-26 04:01:58,855] [INFO]: [INFO] DB_WRITE_OK table=screener_run_map_app rows=3
[2026-01-26 04:01:58,869] [WARNING]: [WARN] DB_SCHEMA_FAILED view=latest_screener_candidates err=must be owner of view latest_screener_candidates

[2026-01-26 04:01:58,933] [INFO]: [INFO] DB_WRITE_OK table=pipeline_health rows=1
[2026-01-26 04:01:58,934] [INFO]: Screener complete: 7756 symbols examined, 7 candidates.
[2026-01-26T04:01:59.469363+00:00] END screener rc=0 secs=985.1
